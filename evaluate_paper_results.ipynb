{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create figures for the paper\n",
    "\n",
    "- test.py needs to be run before.\n",
    "- DATASET_LOCATION needs to be set before.\n",
    "- Model weights need to be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from torchmetrics import Dice\n",
    "\n",
    "from pathlib import Path\n",
    "from src.gleason_data import GleasonX\n",
    "from src.augmentations import basic_transforms_val_test_scaling512, normalize_only_transform\n",
    "from src.model_utils import SoftDICEMetric\n",
    "from src.jdt_losses import SoftCorrectDICEMetric\n",
    "\n",
    "from src.tree_loss import generate_label_hierarchy\n",
    "from  src.gleason_utils import classes_ll1_shortform as class_names\n",
    "\n",
    "from src.jdt_losses import SoftDICECorrectAccuSemiMetric\n",
    "from src.jdt_losses import JDTLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIATIONS\n",
    "\n",
    "from itertools import zip_longest\n",
    "import math\n",
    "from textwrap import wrap\n",
    "from typing import Literal\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import src.augmentations as augmentations\n",
    "import numpy as np\n",
    "from src.gleason_utils import create_composite_plot\n",
    "\n",
    "import ipywidgets as wid\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import colormaps as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(os.environ[\"DATASET_LOCATION\"]) / \"GleasonXAI\"\n",
    "fig_dir = Path('./figures')\n",
    "os.makedirs(fig_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_plot(dataset, idx, ensemble_predictions, individual_predictions, show_ensemble_preds = 0):\n",
    "    \n",
    "    img, masks, background_mask = dataset.__getitem__(idx, False)\n",
    "    org_img = augmentations.basic_transforms_val_test_colorpreserving(image=np.array(dataset.get_raw_image(idx)))[\"image\"]\n",
    "    np_seg = np.array(ensemble_predictions[idx].argmax(dim=0)).astype(np.uint8)\n",
    "\n",
    "    masks = {\"segmentation\": np_seg} | {f\"Annotator {i}\": mask.astype(np.uint8) for i,\n",
    "                                        mask in enumerate(masks)}\n",
    "\n",
    "    sub_ensemble_preds = []\n",
    "    rnd_ensemble_subset = np.random.permutation(show_ensemble_preds)\n",
    "\n",
    "    for i in rnd_ensemble_subset:\n",
    "        np_seg = np.array(individual_predictions[i, idx].argmax(dim=0)).astype(np.uint8)\n",
    "        sub_ensemble_preds.append(np_seg)\n",
    "    \n",
    "\n",
    "    \n",
    "    if len(sub_ensemble_preds) > 0:\n",
    "        masks = {f\"ensemble_pred_{i}\":sub_ensemble_pred for i, sub_ensemble_pred in enumerate(sub_ensemble_preds)} | masks\n",
    "\n",
    "\n",
    "    f = create_composite_plot(dataset, org_img, masks, background_mask.astype(np.uint8), label_level=1, only_show_existing_annotation=True)\n",
    "\n",
    "\n",
    "def composite_prediction_plot(predictions, dataset, indices, mask_background=False, full_legend=True):\n",
    "\n",
    "    num_plots = len(indices)\n",
    "    rows = int(np.ceil(num_plots / 3))  # Assuming 3 columns per row, adjust as needed\n",
    "\n",
    "    # f, axs = plt.subplots(rows, 3, figsize=(12, 4 * rows))\n",
    "\n",
    "    # for idx, ax in zip(indices, axs.flatten()):\n",
    "    for idx in indices:\n",
    "\n",
    "        img, masks, background_mask = dataset.__getitem__(idx, False)\n",
    "        org_img = augmentations.basic_transforms_val_test_colorpreserving(image=np.array(dataset.get_raw_image(idx)))[\"image\"]\n",
    "\n",
    "        background = background_mask if mask_background else None\n",
    "\n",
    "        #out = generate_model_output(model, img, device=device, label_remapping=LABEL_REMAPPING, inferer=SLIDING_WINDOW_INFERER)\n",
    "        out = predictions[idx]\n",
    "        out = torch.nn.functional.softmax(out, 0)\n",
    "        np_seg = np.array(out.argmax(dim=0)).astype(np.uint8)\n",
    "        # out = generate_model_output(model, img, masks, dataset.num_classes)\n",
    "        # np_seg = np.array(out.squeeze(0).argmax(dim=0)).astype(np.uint8)\n",
    "        f = create_composite_plot(dataset, org_img,  {\"segmentation\": np_seg} | {f\"Annotator {i}\": mask for i,\n",
    "                                    mask in enumerate(masks)}, background, only_show_existing_annotation=not full_legend)\n",
    "\n",
    "        return f\n",
    "\n",
    "\n",
    "def create_single_class_acti_maps(predictions, dataset, idx, plot_mode: Literal[\"heatmap\", \"contourf\", \"contour\", \"thresholded\"] = \"contourf\", thresholds: list[float] = None, strip_background=False, plot=True):\n",
    "\n",
    "    img, masks, background_mask = dataset.__getitem__(idx, False)\n",
    "    # org_img = augmentations.basic_transforms_val_test_colorpreserving(image=np.array(dataset.get_raw_image(idx)))[\"image\"]\n",
    "\n",
    "    out = predictions[idx] \n",
    "    out = torch.nn.functional.softmax(out, 0)\n",
    "\n",
    "    np_seg = np.array(out.argmax(dim=0)).astype(np.uint8)\n",
    "\n",
    "    org_img = np.array(dataset.get_raw_image(idx).resize(np_seg.shape))\n",
    "\n",
    "    colormap = ListedColormap(dataset.colormap.colors)\n",
    "    num_class_to_vis = dataset.num_classes\n",
    "\n",
    "    if strip_background:\n",
    "\n",
    "        for mask in masks:\n",
    "            mask += 1\n",
    "            mask[background_mask] = 0\n",
    "\n",
    "        np_seg += 1\n",
    "        np_seg[background_mask] = 0\n",
    "\n",
    "        out[:, torch.tensor(background_mask).bool()] = 0.0\n",
    "\n",
    "        colormap = ListedColormap(np.concatenate([np.array([[0., 0., 0., 1.]]), dataset.colormap.colors]))\n",
    "        num_class_to_vis = dataset.num_classes + 1\n",
    "\n",
    "    f, axes = plt.subplots(2, 3+math.ceil(dataset.num_classes/2), sharex=False, sharey=False, constrained_layout=False, figsize=(12, 4))\n",
    "    f.tight_layout()\n",
    "\n",
    "    axes[0, 0].imshow(org_img)\n",
    "    axes[0, 0].set_title(\"Image\", size=7)\n",
    "    axes[0, 0].set_axis_off()\n",
    "\n",
    "    # axes[1, 0].imshow(img)\n",
    "    axes[1, 0].imshow(np_seg.astype(int), cmap=colormap, vmin=0, vmax=num_class_to_vis - 1, interpolation_stage=\"rgba\")\n",
    "    axes[1, 0].set_title(\"Segmentation\", size=7)\n",
    "    axes[1, 0].set_axis_off()\n",
    "\n",
    "    for sub_ax, mask in zip_longest(list(axes[:, 1:3].flatten()), masks):\n",
    "        sub_ax.set_axis_off()\n",
    "\n",
    "        if mask is not None:\n",
    "            sub_ax.imshow(mask.astype(int), cmap=colormap, vmin=0, vmax=num_class_to_vis - 1,  interpolation_stage=\"rgba\")\n",
    "            sub_ax.set_title(\"Annotation\", size=7)\n",
    "\n",
    "    for i in range(dataset.num_classes):\n",
    "        active_axis = axes[:, 3:].flatten()[i]\n",
    "\n",
    "        class_out = out[i, :].detach().numpy()\n",
    "\n",
    "        if strip_background:\n",
    "            class_out[background_mask] = 0\n",
    "\n",
    "        temp_colormap = ListedColormap(np.concatenate([np.array([[0., 0., 0., 1.]]), dataset.colormap.colors[i].reshape(1, -1)]))\n",
    "\n",
    "        match plot_mode:\n",
    "            case \"heatmap\": active_axis.matshow(class_out, cmap=cm[\"Grays\"].reversed(), vmin=out[out != 0.0].min(), vmax=out.max())\n",
    "            case \"multilabel\": active_axis.matshow(class_out >= 0.32, cmap=temp_colormap)\n",
    "            case \"contour\": active_axis.contour(np.flipud(class_out), cmap=cm[\"Grays\"].reversed(), vmin=0.0, vmax=out.max())\n",
    "            case \"contourf\": active_axis.contourf(np.flipud(class_out), cmap=cm[\"Grays\"].reversed(), vmin=0.0, vmax=out.max())\n",
    "            case \"thresholded\": active_axis.matshow(class_out > thresholds[i], cmap=cm[\"Grays\"].reversed())\n",
    "\n",
    "        if i == 0:\n",
    "            title = \"Benign\"\n",
    "        else:\n",
    "            exp = dataset.explanations[i-1]\n",
    "            classes_named = [\"benign tissue\", \"3 - individual glands\", \"3 - compressed glands\", \"4 - poorly formed glands\",\n",
    "                             \"4 - cribriform glands\", \"4 - glomeruloid glands\", \"5 - group of tumor cells\", \"5 - single cells\", \"5 - cords\", \"5 - comedenocrosis\"]\n",
    "            exp_short = classes_named[i]\n",
    "            title = \"\\n\".join(wrap(str(dataset.exp_grade_mapping[exp]) + \": \" + exp_short, width=20))\n",
    "\n",
    "        active_axis.set_title(title, size=7)\n",
    "        active_axis.set_axis_off()\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        return f, axes\n",
    "\n",
    "\n",
    "def create_simple_seg_anno_plot(predictions, dataset, idx, plot_mode: Literal[\"heatmap\", \"contourf\", \"contour\", \"thresholded\"] = \"contourf\", thresholds: list[float] = None, strip_background=False, plot=True):\n",
    "\n",
    "    img, masks, background_mask = dataset.__getitem__(idx, False)\n",
    "\n",
    "    out = predictions[idx]\n",
    "\n",
    "    out = torch.nn.functional.softmax(out, 0)\n",
    "\n",
    "    np_seg = np.array(out.argmax(dim=0)).astype(np.uint8)\n",
    "\n",
    "    org_img = np.array(dataset.get_raw_image(idx).resize(np_seg.shape))\n",
    "\n",
    "    colormap = ListedColormap(dataset.colormap.colors)\n",
    "    num_class_to_vis = dataset.num_classes\n",
    "\n",
    "    if strip_background:\n",
    "\n",
    "        for mask in masks:\n",
    "            mask += 1\n",
    "            mask[background_mask] = 0\n",
    "\n",
    "        np_seg += 1\n",
    "        np_seg[background_mask] = 0\n",
    "\n",
    "        out[:, torch.tensor(background_mask).bool()] = 0.0\n",
    "\n",
    "        colormap = ListedColormap(np.concatenate([np.array([[0., 0., 0., 1.]]), dataset.colormap.colors]))\n",
    "        num_class_to_vis = dataset.num_classes + 1\n",
    "\n",
    "    f, axes = plt.subplots(1, 5, sharex=False, sharey=False, constrained_layout=False, figsize=(12, 4))\n",
    "    f.tight_layout()\n",
    "    axes[0].imshow(org_img)\n",
    "    axes[0].set_title(\"Image\", size=7)\n",
    "    axes[0].set_axis_off()\n",
    "\n",
    "    axes[1].imshow(np_seg.astype(int), cmap=colormap, vmin=0, vmax=num_class_to_vis - 1, interpolation_stage=\"rgba\")\n",
    "    axes[1].set_title(\"Segmentation\", size=7)\n",
    "    axes[1].set_axis_off()\n",
    "\n",
    "    for sub_ax, mask in zip_longest(axes[2:], masks):\n",
    "        \n",
    "        if sub_ax is None:\n",
    "            continue\n",
    "        sub_ax.set_axis_off()\n",
    "\n",
    "        if mask is not None:\n",
    "            sub_ax.imshow(mask.astype(int), cmap=colormap, vmin=0, vmax=num_class_to_vis - 1,  interpolation_stage=\"rgba\")\n",
    "            sub_ax.set_title(\"Annotation\", size=7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def create_multi_seg_anno_plot(predictions, dataset, idcs, strip_background=False, legend=False, class_names=None):\n",
    "\n",
    "    if class_names is None:\n",
    "        class_names = dataset.classes_named\n",
    "    num_plots = len(idcs)\n",
    "    \n",
    "    f, top_axes = plt.subplots(num_plots, 5, sharex=False, sharey=False, constrained_layout=False, figsize=(10, 2*num_plots))\n",
    "    f.tight_layout()\n",
    "\n",
    "    encountered_classes = set()\n",
    "\n",
    "\n",
    "    if strip_background:\n",
    "        colormap = ListedColormap(np.concatenate([np.array([[0., 0., 0., 1.]]), dataset.colormap.colors]))\n",
    "        num_class_to_vis = dataset.num_classes + 1\n",
    "    else:\n",
    "        colormap = ListedColormap(dataset.colormap.colors)\n",
    "        num_class_to_vis = dataset.num_classes\n",
    "    \n",
    "    for i,idx in enumerate(idcs):\n",
    "\n",
    "        axes = top_axes[i]\n",
    "        \n",
    "        _, masks, background_mask = dataset.__getitem__(idx, False)\n",
    "\n",
    "        out = predictions[idx]  \n",
    "        \n",
    "        out = torch.nn.functional.softmax(out, 0)\n",
    "\n",
    "        np_seg = np.array(out.argmax(dim=0)).astype(np.uint8)\n",
    "\n",
    "        org_img = np.array(dataset.get_raw_image(idx).resize(np_seg.shape))\n",
    "\n",
    "\n",
    "\n",
    "        if strip_background:\n",
    "\n",
    "            for mask in masks:\n",
    "                mask += 1\n",
    "                mask[background_mask] = 0\n",
    "\n",
    "            np_seg += 1\n",
    "            np_seg[background_mask] = 0\n",
    "\n",
    "            out[:, torch.tensor(background_mask).bool()] = 0.0\n",
    "\n",
    "        encountered_classes |= set(np.unique(np_seg))\n",
    "        \n",
    "        for mask in masks:\n",
    "            encountered_classes |= set(np.unique(mask))\n",
    "\n",
    "        # f, axes = plt.subplots(2, 3+math.ceil(dataset.num_classes/2), sharex=False, sharey=False, constrained_layout=False, figsize=(12, 4))\n",
    "        axes[0].imshow(org_img)\n",
    "        #axes[0].set_title(f\"Image {i}\", size=7)\n",
    "        axes[0].set_axis_off()\n",
    "        #axes[0].text(0,0,idx)\n",
    "\n",
    "        # axes[1, 0].imshow(img)\n",
    "        axes[1].imshow(np_seg.astype(int), cmap=colormap, vmin=0, vmax=num_class_to_vis - 1, interpolation_stage=\"rgba\")\n",
    "        #axes[1].set_title(\"Segmentation\", size=7)\n",
    "        axes[1].set_axis_off()\n",
    "\n",
    "        for sub_ax, mask in zip_longest(axes[2:], masks):\n",
    "\n",
    "            if sub_ax is None:\n",
    "                continue\n",
    "            sub_ax.set_axis_off()\n",
    "\n",
    "            if mask is not None:\n",
    "                sub_ax.imshow(mask.astype(int), cmap=colormap, vmin=0, vmax=num_class_to_vis - 1,  interpolation_stage=\"rgba\")\n",
    "                #sub_ax.set_title(\"Annotation\", size=7)\n",
    "\n",
    "    if legend:\n",
    "        if strip_background:\n",
    "            legend_handels = [mpatches.Patch(color=np.array([0., 0., 0., 1.]), label=f\"Background\")]\n",
    "            legend_handels += [mpatches.Patch(color=colormap(dataset.classes_number_mapping[cls]+1), label=cls_renamed if len(cls_renamed) < 60 else cls_renamed[:60]+\"...\")\n",
    "                                for cls, cls_renamed in zip(dataset.classes_named, class_names) if dataset.classes_number_mapping[cls]+1 in encountered_classes]\n",
    "        else:\n",
    "            legend_handels = [mpatches.Patch(color=colormap(dataset.classes_number_mapping[cls]), label=cls_renamed[:40] if len(cls_renamed) < 60 else cls_renamed[:60]+\"...\")\n",
    "                              for cls, cls_renamed in zip(dataset.classes_named, class_names) if dataset.classes_number_mapping[cls] in encountered_classes]\n",
    "\n",
    "\n",
    "        f.legend(handles=legend_handels, loc=\"center left\", fontsize=12, bbox_to_anchor=[1.0,0.5])\n",
    "        # plt.title(test_df[\"TMA\"][0])\n",
    "    print([dataset.classes_named[e-1] for e in encountered_classes if e != 0])\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.03, hspace=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = [\"ll1/CE\", \"ll1/Tree\", \"ll1/SDB\", \"ll0/CE\", \"ll0/SDB\", \"ens/ll1/Tree\", \"ens/ll1/SDB\",\n",
    "                    \"final/ll0/CE\",\n",
    "                    \"final/ll1/CE\",\n",
    "                    \"final/ll0/SDB\",\n",
    "                    \"final/ll1/SDB\",\n",
    "                    \"final/ll1/OHCE\",\n",
    "                    \"final/ll1/SDBML\",\n",
    "                    \"final/ll0/DICE\",\n",
    "                    \"final/ll1/DICE\",\n",
    "                    \"final2/ll1/SDB\",\n",
    "                    \"final2/ll1/CE\",\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model_settings(selected_model, remap_ll0):\n",
    "    label_level = 1 if \"ll1\" in selected_model else 0\n",
    "    eval_on = \"test\"\n",
    "\n",
    "    num_classes = 10 if (label_level == 1 and not remap_ll0) else 4\n",
    "\n",
    "    if remap_ll0:\n",
    "        assert \"ll1\" in selected_model\n",
    "        label_level = 0\n",
    "\n",
    "    data_opts = \"final\" if \"final\" in selected_model else \"final\" if \"final2\" in selected_model else \"org\"\n",
    "\n",
    "\n",
    "    if selected_model == \"ens/ll1/SDB\":\n",
    "        model_paths = [Path(f\"GleasonBackgroundMasking/label_level1/HoleMask/SoftDICEBalancedNoZoomCont-{i}/version_0/\") for i in [1,2,3,4]]\n",
    "        model_paths +=  [Path(f\"GleasonBackgroundMasking/label_level1/HoleMask/SoftDICEBalancedNoZoom-{i}/version_0/\") for i in [1, 2,3]]\n",
    "\n",
    "    elif selected_model == \"ens/ll1/Tree\":\n",
    "        model_paths = [Path(f\"GleasonBackgroundMasking/label_level1/HoleMask/FinalTreeLossNoZoomCont-{i}/version_0/\") for i in [1, 2, 3, 4]]\n",
    "        model_paths +=  [Path(f\"GleasonBackgroundMasking/label_level1/HoleMask/NoZoomFinalTreeLoss-{i}/version_0/\") for i in [1, 2,3]]\n",
    "\n",
    "    elif selected_model == \"ll1/CE\":\n",
    "        model_paths = [Path(f\"GleasonBackgroundMasking/label_level1/HoleMask/NoZoomFinalCE-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "    elif selected_model == \"ll1/Tree\":\n",
    "        model_paths = [Path(f\"GleasonBackgroundMasking/label_level1/HoleMask/NoZoomFinalTreeLoss-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "    elif selected_model == \"ll1/SDB\":\n",
    "        model_paths = [Path(f\"GleasonBackgroundMasking/label_level1/HoleMask/SoftDICEBalancedNoZoom-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "    elif selected_model == \"ll0/CE\":\n",
    "        model_paths = [Path(f\"GleasonBackgroundMasking/label_level0/HoleMask/NoZoomFinalCE-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "    elif selected_model == \"ll0/SDB\":\n",
    "        model_paths = [Path(f\"GleasonBackgroundMasking/label_level0/HoleMask/SoftDICEBalancedNoZoom-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "    elif selected_model == \"final/ll0/CE\":\n",
    "        model_paths = [Path(f\"GleasonFinal/label_level0/CE-{i}/version_0/\") for i in [1,2,3]]\n",
    "\n",
    "    elif selected_model == \"final/ll1/CE\":\n",
    "        model_paths = [Path(f\"GleasonFinal/label_level1/CE-{i}/version_0/\") for i in [1,2,3]]\n",
    "\n",
    "    elif selected_model == \"final/ll0/SDB\":\n",
    "        model_paths = [Path(f\"GleasonFinal/label_level0/SoftDiceBalanced-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "    elif selected_model == \"final/ll1/SDB\":\n",
    "        model_paths = [Path(f\"GleasonFinal/label_level1/SoftDiceBalanced-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "    elif selected_model == \"final/ll0/OHCE\":\n",
    "        model_paths = [Path(f\"GleasonFinal/label_level0/OH_CE-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "    elif selected_model == \"final/ll1/OHCE\":\n",
    "        model_paths = [Path(f\"GleasonFinal/label_level1/OH_CE-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "    elif selected_model == \"final/ll1/SDBML\":\n",
    "        model_paths = [Path(f\"GleasonFinal/label_level1/SoftDiceBalancedMultiLevel-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "    elif selected_model == \"final/ll0/DICE\":\n",
    "        model_paths = [Path(f\"GleasonFinal/label_level0/DICE-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "    elif selected_model == \"final/ll1/DICE\":\n",
    "        model_paths = [Path(f\"GleasonFinal/label_level1/DICE-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "    \n",
    "    elif selected_model == \"final2/ll1/SDB\":\n",
    "        model_paths = [Path(f\"GleasonFinal2/label_level1/SoftDiceBalanced-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "    \n",
    "    elif selected_model == \"final2/ll1/CE\":\n",
    "        model_paths = [Path(f\"GleasonFinal2/label_level1/CE-{i}/version_0/\") for i in [1, 2, 3]]\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError()\n",
    "\n",
    "    preds_paths = []\n",
    "    for path in model_paths:\n",
    "        assert (base_path/path).exists(), f\"Could not find {str(base_path/path)}\"\n",
    "        assert (base_path/path/\"preds\"/f\"pred_{eval_on}.pt\").exists(), base_path/path/\"preds\"/f\"pred_test.pt\"\n",
    "        preds_paths.append(base_path/path/\"preds\"/f\"pred_{eval_on}.pt\")\n",
    "        \n",
    "    data_options = {\"org\": {\"scaling\": \"1024\", \"transforms\": basic_transforms_val_test_scaling512, \"label_level\": label_level, \"create_seg_masks\": True, \"tissue_mask_kwargs\": {\"open\": False, \"close\": False, \"flood\": False}},\n",
    "                    \"final\": {\"scaling\": \"MicronsCalibrated\", \"transforms\": normalize_only_transform, \"label_level\": label_level, \"create_seg_masks\": True, \"tissue_mask_kwargs\": {\"open\": False, \"close\": False, \"flood\": False}, \"drawing_order\": \"grade_frame_order\", \"explanation_file\": \"final_filtered_explanations_df.csv\", \"data_split\": (0.7, 0.15, 0.15)},\n",
    "                    }\n",
    "\n",
    "    # data = GleasonX(base_path, split=\"test\", scaling=\"1024\", transforms=basic_transforms_val_test_scaling512, label_level=label_level, create_seg_masks=True, tissue_mask_kwargs={\"open\": False, \"close\":False, \"flood\":False})\n",
    "    data = GleasonX(base_path, split=\"test\", **data_options[data_opts])\n",
    "\n",
    "    labels = []\n",
    "    bgs = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        _, label, background = data[i]\n",
    "        labels.append(label)\n",
    "        bgs.append(background)\n",
    "\n",
    "\n",
    "    def remapping_function(out):\n",
    "    \n",
    "        out_remappings = generate_label_hierarchy(out, data.exp_numbered_lvl_remapping, start_level=1)\n",
    "\n",
    "        return out_remappings[0]\n",
    "\n",
    "    return model_paths, preds_paths,  label_level, num_classes, data, labels, bgs, remapping_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "from src.model_utils import L1CalibrationMetric\n",
    "\n",
    "def get_all_metrics_from_list(preds, labels, bgs):\n",
    "\n",
    "    num_classes = preds[0].shape[0]\n",
    "    \n",
    "    d_mac = Dice(num_classes=num_classes, average=\"macro\")\n",
    "    d_mic = Dice(num_classes=num_classes, average=\"micro\")\n",
    "    b_acc = Accuracy(task=\"multiclass\", num_classes=num_classes, average=\"macro\")\n",
    "    acc = Accuracy(task=\"multiclass\", num_classes=num_classes, average=\"micro\")\n",
    "    \n",
    "    emd = []\n",
    "    L1 = L1CalibrationMetric()\n",
    "    mDICED = SoftDICECorrectAccuSemiMetric()\n",
    "\n",
    "    for i in tqdm(range(len(preds))):\n",
    "        pred = preds[i]\n",
    "        bg = bgs[i]\n",
    "        label = labels[i]\n",
    "        fg = ~bg\n",
    "\n",
    "        emd.append(((pred[:, fg] - label[:, fg]).abs().sum(dim=1)/2)/fg.sum())\n",
    "\n",
    "        label_max = torch.max(label, dim=0)[0]\n",
    "        duplicated_max = torch.sum(label == label_max.unsqueeze(0), dim=0) > 1\n",
    "\n",
    "        unique_max = ~duplicated_max\n",
    "\n",
    "        unique_max_fg = torch.logical_and(fg, unique_max)\n",
    "\n",
    "        unique_max_fg_pred_maj = pred[:, unique_max_fg].unsqueeze(0).argmax(dim=1)\n",
    "        unique_max_fg_label_maj = label[:, unique_max_fg].unsqueeze(0).argmax(dim=1)\n",
    "\n",
    "        d_mac.update(unique_max_fg_pred_maj, unique_max_fg_label_maj)\n",
    "        d_mic.update(unique_max_fg_pred_maj, unique_max_fg_label_maj)\n",
    "        b_acc.update(unique_max_fg_pred_maj, unique_max_fg_label_maj)\n",
    "        acc.update(unique_max_fg_pred_maj, unique_max_fg_label_maj)\n",
    "\n",
    "        L1.update(pred[:, fg].unsqueeze(0), label[:, fg].unsqueeze(0))\n",
    "        mDICED.update(pred[:,fg].unsqueeze(0), label[:,fg].unsqueeze(0))\n",
    "        #corrected_masked_mIoUD.update(preds_ensemble[i].unsqueeze(0), labels[i].unsqueeze(0), keep_mask=~rel_bg)\n",
    "\n",
    "\n",
    "    emd = torch.stack(emd).mean(dim=0)\n",
    "    emd = emd.sum()\n",
    "\n",
    "    d_mac = d_mac.compute()\n",
    "    d_mic = d_mic.compute()\n",
    "    mDICED = mDICED.compute()\n",
    "    L1 = L1.compute()\n",
    "    acc = acc.compute()\n",
    "    b_acc = b_acc.compute()\n",
    "\n",
    "    return {\"mDICED\":mDICED.item(), \"L1\":emd.item(), \"L1Compare\":L1.item(),  \"DICEmacro_unique_max\":d_mac.item(), \"DICE_unique_max\":d_mic.item(), \"Acc\":acc.item(), \"Bacc\":b_acc.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_metrics(preds_path, labels, bgs, remap=False):\n",
    "\n",
    "    mets = []\n",
    "\n",
    "    for p_path in preds_path:\n",
    "        print(f\"Loading {p_path.parents[1]}\")\n",
    "        preds = torch.load(base_path/p_path)\n",
    "        print(\"Softmax\")\n",
    "        preds = [torch.nn.functional.softmax(img_pred.float().squeeze(0), dim=0) for img_pred in preds]\n",
    "\n",
    "        if remap:\n",
    "            print(\"Remapping to LL0\")\n",
    "            preds = [remap(pred.unsqueeze(0)).squeeze(0) for pred in preds]\n",
    "            \n",
    "        print(\"Computing metrics\")\n",
    "        mets.append(get_all_metrics_from_list(preds, labels, bgs))\n",
    "\n",
    "\n",
    "    print(\"Results\")\n",
    "    met_df = pd.DataFrame(mets).aggregate([\"mean\", \"std\"])\n",
    "    print(met_df)\n",
    "\n",
    "    return met_df\n",
    "\n",
    "def get_save_path(model_name, remapped):\n",
    "    \n",
    "    save_name = model_name.replace(\"/\", \"_\")\n",
    "    remap_str = \"_remaped\" if remapped else \"\"\n",
    "    save_path = Path(f\"./results/metrics_final/{save_name}{remap_str}.csv\")\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_test = [s for s in available_models if \"final2/ll1/SDB\" in s]#[s for s in available_models if \"final2/\" in s]\n",
    "\n",
    "for selected_model in models_to_test:\n",
    "    \n",
    "    print(f\"selected_model: {selected_model}\")\n",
    "    assert selected_model in available_models\n",
    "    remap_ll0 = False\n",
    "    print(\"No Remap\")\n",
    "\n",
    "    save_path = get_save_path(selected_model, remap_ll0)\n",
    "\n",
    "    if not save_path.exists():\n",
    "        print(\"Loading model_paths and data\")\n",
    "        model_paths, preds_paths, label_level, num_classes, data, labels, bgs, remapping_function = get_model_settings(selected_model, remap_ll0)\n",
    "        df = compute_model_metrics(preds_paths, labels, bgs, remap=False)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(save_path)\n",
    "    else:\n",
    "            print(\"Skipping due to existing save_file\")\n",
    "    \n",
    "    if \"ll1\" in selected_model:\n",
    "        remap_ll0 = True\n",
    "        print(\"Remap to LL1\")\n",
    "        \n",
    "        save_path = get_save_path(selected_model, remap_ll0)\n",
    "        if not save_path.exists():\n",
    "            print(\"Loading model_paths and data\")\n",
    "            model_paths, preds_paths, label_level, num_classes, data, labels, bgs, remapping_function = get_model_settings(selected_model, remap_ll0)\n",
    "            df = compute_model_metrics(preds_paths, labels, bgs, remap=remapping_function)\n",
    "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            df.to_csv(save_path)\n",
    "        else:\n",
    "            print(\"Skipping due to existing save_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_model_settings(\"final2/ll1/SDB\", False)\n",
    "_, p_paths, _, _, data, labels, bgs, remapping_function  = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.load(base_path/p_paths[0])\n",
    "\n",
    "preds2 = torch.load(base_path/p_paths[1])\n",
    "\n",
    "for i,pred2 in enumerate(preds2):\n",
    "    preds[i] += pred2\n",
    "\n",
    "preds2 = None\n",
    "preds2 = torch.load(base_path/p_paths[2])\n",
    "\n",
    "for i, pred2 in enumerate(preds2):\n",
    "    preds[i] += pred2\n",
    "\n",
    "preds2 = None\n",
    "\n",
    "print(\"Softmax\")\n",
    "preds = [torch.nn.functional.softmax(img_pred.float().squeeze(0), dim=0) for img_pred in preds]\n",
    "\n",
    "if False:\n",
    "    print(\"Remapping to LL0\")\n",
    "    preds = [remapping_function(pred.unsqueeze(0)).squeeze(0) for pred in preds]\n",
    "preds_ensemble=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute outputs\n",
    "STRIP_BACKGROUND = True\n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "pix_freq = torch.zeros(num_classes, dtype=torch.int)\n",
    "max_freq = torch.zeros(num_classes, dtype=torch.int)\n",
    "pred_freq = torch.zeros(num_classes, dtype=torch.int)\n",
    "ml_pred_freq = torch.zeros(num_classes, dtype=torch.int)\n",
    "\n",
    "one_annotator_pred_freq = torch.zeros(num_classes, dtype=torch.int)\n",
    "\n",
    "conf_matrix = ConfusionMatrix(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "for p_path in p_paths:\n",
    "\n",
    "    preds = torch.load(base_path/p_path)\n",
    "    preds = [torch.nn.functional.softmax(img_pred.float().squeeze(0), dim=0) for img_pred in preds]\n",
    "\n",
    "        \n",
    "    for i in tqdm(range(len(data))):\n",
    "\n",
    "        out = preds[i]\n",
    "\n",
    "        background_mask = bgs[i]\n",
    "        mask = labels[i]\n",
    "        if STRIP_BACKGROUND:\n",
    "            foreground_mask = ~background_mask.bool()\n",
    "        else:\n",
    "            foreground_mask = torch.ones_like(background_mask).bool()\n",
    "\n",
    "        label_max = torch.max(mask, dim=0)[0]\n",
    "        duplicated_max = torch.sum(mask == label_max.unsqueeze(0), dim=0) > 1\n",
    "\n",
    "        unique_max = ~duplicated_max\n",
    "\n",
    "        unique_max_fg = torch.logical_and(foreground_mask, unique_max)\n",
    "\n",
    "        mask_unique = mask[:, unique_max_fg]\n",
    "        out_unique = out[:, unique_max_fg]\n",
    "\n",
    "        mask = mask[:, foreground_mask].flatten(start_dim=1)\n",
    "        out = out[:, foreground_mask].flatten(start_dim=1)\n",
    "\n",
    "        pix_freq += torch.sum((mask > 0), dim=(1))\n",
    "        max_freq += torch.bincount(torch.argmax(mask_unique, dim=0).reshape(-1), minlength=num_classes)\n",
    "        pred_freq += torch.bincount(torch.argmax(out,  dim=0).reshape(-1), minlength=num_classes)\n",
    "        one_annotator_pred_freq += torch.sum(out >= 0.33, dim=(1))  # torch.bincount(torch.argmax(out,  dim=0).reshape(-1), minlength=num_classes)\n",
    "\n",
    "        conf_matrix(out_unique.argmax(dim=0), mask_unique.argmax(dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute outputs\n",
    "STRIP_BACKGROUND = True\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "pix_freq = torch.zeros(num_classes, dtype=torch.int)\n",
    "max_freq = torch.zeros(num_classes, dtype=torch.int)\n",
    "pred_freq = torch.zeros(num_classes, dtype=torch.int)\n",
    "ml_pred_freq = torch.zeros(num_classes, dtype=torch.int)\n",
    "\n",
    "one_annotator_pred_freq = torch.zeros(num_classes, dtype=torch.int)\n",
    "\n",
    "conf_matrices = [ConfusionMatrix(task=\"multiclass\", num_classes=num_classes) for _ in range(len(p_paths))]\n",
    "\n",
    "for i, p_path in enumerate(p_paths):\n",
    "\n",
    "    count_unique_max = 0.0\n",
    "    count_foreground = 0.0\n",
    "    count_pixels = 0.0\n",
    "\n",
    "    conf_matrix = conf_matrices[i]\n",
    "\n",
    "    preds = torch.load(base_path/p_path)\n",
    "    preds = [torch.nn.functional.softmax(img_pred.float().squeeze(0), dim=0) for img_pred in preds]\n",
    "\n",
    "    for i in tqdm(range(len(data))):\n",
    "\n",
    "        out = preds[i]\n",
    "\n",
    "        background_mask = bgs[i]\n",
    "        mask = labels[i]\n",
    "        if STRIP_BACKGROUND:\n",
    "            foreground_mask = ~background_mask.bool()\n",
    "        else:\n",
    "            foreground_mask = torch.ones_like(background_mask).bool()\n",
    "\n",
    "        label_max = torch.max(mask, dim=0)[0]\n",
    "        duplicated_max = torch.sum(mask == label_max.unsqueeze(0), dim=0) > 1\n",
    "\n",
    "        unique_max = ~duplicated_max\n",
    "\n",
    "        unique_max_fg = torch.logical_and(foreground_mask, unique_max)\n",
    "\n",
    "        count_unique_max += torch.logical_and(foreground_mask, unique_max).sum()\n",
    "        count_foreground += foreground_mask.sum()\n",
    "        count_pixels += foreground_mask.numel()\n",
    "\n",
    "\n",
    "\n",
    "        mask_unique = mask[:, unique_max_fg]\n",
    "        out_unique = out[:, unique_max_fg]\n",
    "\n",
    "        mask = mask[:, foreground_mask].flatten(start_dim=1)\n",
    "        out = out[:, foreground_mask].flatten(start_dim=1)\n",
    "\n",
    "        pix_freq += torch.sum((mask > 0), dim=(1))\n",
    "        max_freq += torch.bincount(torch.argmax(mask_unique, dim=0).reshape(-1), minlength=num_classes)\n",
    "        pred_freq += torch.bincount(torch.argmax(out,  dim=0).reshape(-1), minlength=num_classes)\n",
    "        one_annotator_pred_freq += torch.sum(out >= 0.33, dim=(1))  # torch.bincount(torch.argmax(out,  dim=0).reshape(-1), minlength=num_classes)\n",
    "\n",
    "        conf_matrix(out_unique.argmax(dim=0), mask_unique.argmax(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the number of foreground and unique_max pixels.\n",
    "\n",
    "# data = GleasonX(base_path, split=\"test\", scaling=\"1024\", transforms=basic_transforms_val_test_scaling512, label_level=label_level, create_seg_masks=True, tissue_mask_kwargs={\"open\": False, \"close\":False, \"flood\":False})\n",
    "data_all = GleasonX(base_path, split=\"all\",  **{\"scaling\": \"MicronsCalibrated\", \"transforms\": normalize_only_transform, \"label_level\": 1, \"create_seg_masks\": True, \"tissue_mask_kwargs\": {\n",
    "                \"open\": False, \"close\": False, \"flood\": False}, \"drawing_order\": \"grade_frame_order\", \"explanation_file\": \"final_filtered_explanations_df.csv\", \"data_split\": (0.7, 0.15, 0.15)}\n",
    "                )\n",
    "\n",
    "count_unique_max = 0.0\n",
    "count_foreground = 0.0\n",
    "count_pixels = 0.0\n",
    "count_agg_annotators = torch.zeros(4)\n",
    "\n",
    "label_counts = torch.zeros(data_all.num_classes, 4)\n",
    "STRIP_BACKGROUND = True\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "for i in tqdm(range(len(data_all))):\n",
    "\n",
    "    _, mask, background_mask = data_all[i]\n",
    "    \n",
    "    if STRIP_BACKGROUND:\n",
    "        foreground_mask = ~background_mask.bool()\n",
    "    else:\n",
    "        foreground_mask = torch.ones_like(background_mask).bool()\n",
    "\n",
    "    mask = (mask *3).int()\n",
    "    mask_fg = mask[:, foreground_mask].flatten(start_dim=1)\n",
    "\n",
    "    count_agg_annotators += torch.bincount(mask_fg.max(dim=0)[0], minlength=4)\n",
    "    for c in range(data_all.num_classes):\n",
    "        occ_count = torch.bincount(mask_fg[c].flatten(), minlength=4)\n",
    "        label_counts[c,:] += occ_count\n",
    "\n",
    "    \n",
    "    label_max = torch.max(mask, dim=0)[0]\n",
    "    duplicated_max = torch.sum(mask == label_max.unsqueeze(0), dim=0) > 1\n",
    "\n",
    "    unique_max = ~duplicated_max\n",
    "\n",
    "    unique_max_fg = torch.logical_and(foreground_mask, unique_max)\n",
    "\n",
    "    count_unique_max += torch.logical_and(foreground_mask, unique_max).sum()\n",
    "    count_foreground += foreground_mask.sum()\n",
    "    count_pixels += foreground_mask.numel()\n",
    "\n",
    "count_unique_max/count_foreground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ll0: [0.0000, 0.0246, 0.3623, 0.6130]\n",
    "ll1: [0.0000, 0.1359, 0.4107, 0.4535]\n",
    "ll2: [0.0000, 0.3224, 0.3780, 0.2996]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_agreement = label_counts[:,1:]/label_counts[:,1:].sum(dim=1).reshape(-1,1)\n",
    "percentages = label_counts[:, 1:].sum(dim=1)/label_counts[:, :].sum(dim=1)\n",
    "\n",
    "for i,c in enumerate(class_names):\n",
    "    s = f\"{c}: {label_counts[i, 1:].sum()/label_counts[i,:].sum():0.2f}, {list(pixel_agreement[i].numpy()*100)}\"\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8), gridspec_kw={'width_ratios': [1, 1], 'hspace':-4.0}, sharey=True)\n",
    "\n",
    "fontsize_axis = 22\n",
    "fontsize=20\n",
    "fontsize_label = 20\n",
    "fontsize_bar = 20\n",
    "\n",
    "\n",
    "cmap = ListedColormap(cm[\"Blues\"](np.linspace(0, 1, 1000))[:-250])\n",
    "\n",
    "# First subplot: pixel agreement as a heatmap on the left\n",
    "im = ax1.matshow(pixel_agreement*100, cmap=cmap, aspect='auto')\n",
    "\n",
    "# Set xtick labels for the heatmap as 1, 2, and 3\n",
    "ax1.set_xticks(np.arange(pixel_agreement.shape[1]))\n",
    "ax1.set_xticklabels([1, 2, 3], fontsize=fontsize)\n",
    "ax1.set_xlabel(\"Number of agreeing annotators\", fontsize=fontsize_axis)\n",
    "ax1.set_ylabel(\"Explanation\", fontsize=fontsize_axis)\n",
    "ax1.set_yticks(np.arange(len(class_names)))\n",
    "ax1.set_yticklabels(class_names, fontsize=fontsize)\n",
    "# ax1.set_title(\"Number of annotators per explanation annotated pixels\")\n",
    "# Loop over data dimensions and create text annotations for the heatmap\n",
    "for i in range(pixel_agreement.shape[0]):\n",
    "    for j in range(pixel_agreement.shape[1]):\n",
    "        ax1.text(j, i, f\"{pixel_agreement[i, j]*100:.2f}%\",\n",
    "                 ha=\"center\", va=\"center\", color=\"black\", fontsize=fontsize_label)\n",
    "\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['left'].set_visible(False)\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "#ax2.spines['left'].set_visible(False)\n",
    "#ax2.spines['bottom'].set_visible(False)\n",
    "\n",
    "\n",
    "# Add color bar for pixel agreement\n",
    "#cbar = fig.colorbar(im, ax=ax1)\n",
    "\n",
    "# Second subplot: percentages as a horizontal bar chart on the right\n",
    "ax2.barh(class_names, percentages, color='lightskyblue')\n",
    "\n",
    "for i, p in enumerate(percentages):\n",
    "        if i in [2, 5, 7]:\n",
    "            ax2.text(\n",
    "                percentages[i].item()/2 + 0.02,# max(percentages[i].item()/2, 0.02) + 0.02,\n",
    "                i,\n",
    "                f\"{percentages[i].item()*100:.2f}\",\n",
    "                ha='left',\n",
    "                va='center',\n",
    "                fontsize=fontsize_bar\n",
    "            )\n",
    "        elif i == 9:\n",
    "             ax2.text(\n",
    "                percentages[i].item()/2 + 0.03,# max(percentages[i].item()/2, 0.02) + 0.02,\n",
    "                i,\n",
    "                f\"{percentages[i].item()*100:.2f}\",\n",
    "                ha='left',\n",
    "                va='center',\n",
    "                fontsize=fontsize_bar\n",
    "            )\n",
    "        else:\n",
    "            ax2.text(\n",
    "                max(percentages[i].item()/2, 0.02),\n",
    "                i,\n",
    "                f\"{percentages[i].item()*100:.2f}\",\n",
    "                ha='center',\n",
    "                va='center',\n",
    "                fontsize=fontsize_bar\n",
    "            )\n",
    "\n",
    "ax2.set_xlabel(\"% of foreground pixels\", fontsize=fontsize_axis)\n",
    "ax2.set_xticks([0.1,0.2,0.3,0.4,0.5], [\"10%\", \"20%\", \"30%\", \"40%\", \"50%\"], fontsize=fontsize_label)\n",
    "# Invert y-axis to match the order of class names\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "# Hide y-labels for the barplot\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "# ax2.set_title(\"Percentage of foreground pixels annotated for an explanation\")\n",
    "\n",
    "\n",
    "# Adjust layout to ensure everything fits\n",
    "ax1.invert_yaxis()\n",
    "ax1.xaxis.set_ticks_position('bottom')  # Ensure x-ticks are at the bottom\n",
    "ax1.text(-1.0, -1, \"a)\", size=24)\n",
    "ax2.text(-0.1, -1, \"b)\", size=24)\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig(\"figures/pixelagreement.svg\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts.sum(dim=1)/count_foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmm = torch.stack([c.compute() for c in conf_matrices], dim=0).float()\n",
    "ccmm = ccmm/ccmm.sum(dim=2).reshape(3,10,1)\n",
    "print(ccmm.float().mean(dim=0).diag())\n",
    "print(ccmm.float().std(dim=0).diag())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor([6.8426e-01, 7.3834e-01, 7.5832e-05, 4.4400e-01, 7.2964e-01, 0.0000e+00,\n",
    "        6.7376e-01, 0.0000e+00, 7.2274e-01, 1.0153e-03])\n",
    "tensor([0.0169, 0.0266, 0.0001, 0.0118, 0.0505, 0.0000, 0.0270, 0.0000, 0.0410,\n",
    "        0.0018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccmm.sum(dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "classes_named = data.classes_named\n",
    "classes_named = [\"benign tissue\", \"3 - individual glands\", \"3 - compressed glands\", \"4 - poorly formed glands\",\n",
    "                 \"4 - cribriform glands\", \"4 - glomeruloid glands\", \"5 - group of tumor cells\", \"5 - single cells\", \"5 - cords\", \"5 - comedenocrosis\"]\n",
    "confm = ccmm.float().mean(dim=0)\n",
    "\n",
    "confm_normed = confm / confm.sum(dim=1).reshape(-1, 1)\n",
    "confm_normed = (confm_normed * 1000).round().long()\n",
    "\n",
    "confm_expanded = confm_normed\n",
    "original_cmap = cm.get_cmap(\"Blues\")\n",
    "im = plt.matshow(confm_expanded, cmap=LinearSegmentedColormap.from_list(\"Blues_80\", original_cmap(np.linspace(0, 0.7, 256))))\n",
    "\n",
    "for (i, j), val in np.ndenumerate(confm_expanded):\n",
    "    if val/10 < 0.01:\n",
    "        s = \"0\"\n",
    "    else:\n",
    "        s = f'{val/10:.1f}'\n",
    "    plt.text(j, i, s, ha='center', va='center', color='black', size=11)\n",
    "\n",
    "# plt.colorbar(im)\n",
    "plt.xticks(range(num_classes), list(map(lambda x: x, classes_named)),  # + [\"Proportion\"],\n",
    "           rotation=45, rotation_mode=\"anchor\", ha=\"right\", va=\"center_baseline\", fontsize=16)\n",
    "\n",
    "plt.yticks(range(num_classes), list(map(lambda x: x, classes_named))  # + [\"Proportion\"]\n",
    "           , rotation=45, fontsize=16)\n",
    "plt.tick_params(axis=\"x\", bottom=True, top=False, labelbottom=True, labeltop=False)\n",
    "\n",
    "plt.ylabel(\"Annotations\", fontsize=22)\n",
    "plt.xlabel(\"Predictions\", fontsize=22)\n",
    "\n",
    "\n",
    "# Adding grey unfilled squares on the diagonal\n",
    "diagonal_boxes = [\n",
    "    (0, 0, 1, 1),\n",
    "    (1, 1, 2, 2),\n",
    "    (3, 3, 3, 3),\n",
    "    (6, 6, 4, 4),  \n",
    "\n",
    "]\n",
    "\n",
    "for x, y, width, height in diagonal_boxes:\n",
    "    rect = Rectangle((y - 0.5, x - 0.5), width, height, fill=False, edgecolor='grey', linewidth=2)\n",
    "    plt.gca().add_patch(rect)\n",
    "\n",
    "plt.savefig(fig_dir / \"confmatrix.svg\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class annotation and prediction frequency\n",
    "\n",
    "a = torch.sum(torch.stack([pred.sum(dim=(1, 2)) for pred in preds]),dim=0)\n",
    "a /= a.sum()\n",
    "\n",
    "b = torch.sum(torch.stack([label.sum(dim=(1, 2)) for label in labels]), dim=0)\n",
    "\n",
    "b /= b.sum()\n",
    "\n",
    "\n",
    "bar_width = 0.15\n",
    "plt.bar(np.arange(num_classes)-1.7*bar_width, b, label=\"soft label probability mass\", width=bar_width)\n",
    "plt.bar(np.arange(num_classes)-0.7*bar_width, a, label=\"predicted probability mass\", width=bar_width, color='lightslategray')\n",
    "\n",
    "plt.bar(np.arange(num_classes)+0.7*bar_width, max_freq/torch.sum(max_freq), label=\"annotator majority vote\", width=bar_width, color='skyblue')\n",
    "# plt.bar(np.arange(num_classes)+1.5*bar_width, one_annotator_pred_freq/torch.sum(max_freq), label=\"one_annotator_pred_freq\", width=bar_width)\n",
    "plt.bar(np.arange(num_classes)+1.7*bar_width, pred_freq/torch.sum(pred_freq), label=\"prediction argmax\", width=bar_width, color='lightgray')\n",
    "\n",
    "# plt.yscale(\"log\")\n",
    "_ = plt.legend(fontsize=14)\n",
    "_ = plt.xticks(np.arange(num_classes), list(map(lambda x: x[:24], classes_named)), rotation=45, ha=\"right\", rotation_mode=\"anchor\", fontsize=18)\n",
    "_ = plt.yticks(fontsize=18)\n",
    "_ = plt.xlabel(\"Explanation\", fontsize=20)\n",
    "_ = plt.ylabel(\"Proportion\", fontsize=20)\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', linewidth=0.5, color='lightgray')\n",
    "\n",
    "plt.savefig(fig_dir / \"proportions.svg\", dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agreement and Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "in_path = Path(\"./output\")\n",
    "out_path = Path(\"./output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_in_path = Path(os.environ[\"DATASET_LOCATION\"]) / \"GleasonXAI\"\n",
    "dataset = GleasonX(creation_in_path, split='all', scaling='MicronsCalibrated', label_level=1, create_seg_masks=True, drawing_order='grade_frame_order', explanation_file='final_filtered_explanations_df.csv', data_split=[0.7, 0.15, 0.15], tissue_mask_kwargs={'open': False, 'close':False, 'flood':False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fleiss Kappa Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from calculate_fleiss_kappa import calculate_kappa_per_group_and_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "use_sub_expl = True\n",
    "prefix = \"pattern\" if use_sub_expl == None else \"sub-expl\" if use_sub_expl == True else \"expl\"\n",
    "\n",
    "if not (in_path / prefix / f\"{prefix}_kappas.csv\").exists():\n",
    "    random.seed(42)\n",
    "    calculate_kappa_per_group_and_label(dataset.df, in_path, use_sub_explanations=use_sub_expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappas_df = pd.read_csv(in_path / prefix /  f\"{prefix}_kappas.csv\")\n",
    "renamed_labels = np.load(in_path / prefix / f\"{prefix}_kappas_y-lables.npy\")\n",
    "\n",
    "figsize = (6, 2.6) if use_sub_expl == None else (5,16) if use_sub_expl == True else (10, 9)\n",
    "plt.figure(figsize=(figsize))\n",
    "ax_bp = sns.boxplot(data=kappas_df.T[1:], color='lightskyblue', showfliers=False, width=0.5, native_scale=False, orient='h') #data=kappas_df.T, palette=cmap\n",
    "plt.xlim(-0.3, 1.1)\n",
    "plt.grid(axis='x', linestyle='--', linewidth=0.5, color='lightgray')\n",
    "ax_bp.set_yticklabels(renamed_labels)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=18)\n",
    "plt.yticks(fontsize=22)\n",
    "sns.stripplot(data=kappas_df.T[1:], color='lightskyblue', jitter=False, linewidth=1, orient='h')\n",
    "sns.boxplot(data=kappas_df.T[1:], showfliers=False, medianprops={'visible': False}, showbox=False, showcaps=False, width=0.5, native_scale=False, orient='h', showmeans=True, meanprops={\"marker\":\"D\",\"markerfacecolor\":\"white\", \"markeredgecolor\":\"gray\"}, zorder=10) #data=kappas_df.T, palette=cmap\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / f\"{prefix}_boxplot_kappas.svg\", dpi=1000)\n",
    "\n",
    "# plt.clf()\n",
    "# plt.cla()\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rater Agrement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculate_dataset_characteristics import agreement_occurrence_per_class, plot_three_rater_agreement_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_sub_expl = None\n",
    "prefix = 'expl' if use_sub_expl == False else 'sub-expl' if use_sub_expl == True else 'grade'\n",
    "ylbl = 'Explanation' if use_sub_expl == False else 'Sub-Explanation' if use_sub_expl == True else 'Gleason Pattern'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "if not (in_path / f\"{prefix}_rater_agreement.csv\").exists():\n",
    "     ca_dict = (agreement_occurrence_per_class(dataset.df, use_sub_expl, True))\n",
    "     plot_three_rater_agreement_occurrence(ca_dict, dataset.df,  in_path, use_sub_expl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = pd.read_csv(in_path / f\"{prefix}_rater_agreement.csv\")\n",
    "fig_size = (7, 15) if use_sub_expl == True else (10,9) if use_sub_expl == False else (6.3, 3)\n",
    "fig, ax = plt.subplots(figsize=fig_size)\n",
    "ax = sns.heatmap(rdf.T[1:], annot=True, fmt='g', cmap='Blues', square=False, cbar=False, annot_kws={\"size\": 14 if use_sub_expl == True else 22 }, linewidths=.5)#cbar_kws={\"shrink\": 0.2})\n",
    "#plt.title('co-occurence of label decisions between three raters\\n(per label)')\n",
    "plt.xlabel('Number of Annotators', fontsize=22)\n",
    "plt.ylabel(ylbl, fontsize=22)\n",
    "plt.xticks(fontsize=22)\n",
    "plt.yticks(fontsize=22)\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation='horizontal')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / f\"{prefix}_agreement_occurences.png\", dpi=1000)\n",
    "# plt.cla()\n",
    "# plt.clf()\n",
    "# plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image vs Annotator Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculate_dataset_characteristics import compare_tma_and_explanation_grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if not (in_path / f\"image_vs_annotation_grade.csv\").exists():\n",
    "    compare_tma_and_explanation_grade(dataset.df, in_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_df = pd.read_csv(in_path / f\"image_vs_annotation_grade.csv\").iloc[:,1:]\n",
    "plt.figure(figsize=(3.5,3))\n",
    "sns.heatmap(cm_df, annot=True, fmt='g', cmap='Blues', cbar=False, square=True, annot_kws={\"size\": 14}, linewidths=.5)\n",
    "# plt.title(\"Confusion Matrix: TMA grade to Explanation Grade\")\n",
    "plt.xlabel('Annotation Gleason pattern', fontsize=14)\n",
    "plt.ylabel('Image score', fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / \"cm_class_comparison.png\", dpi=1000)\n",
    "\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calculate_dataset_characteristics import get_class_cooccurrence_between_labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_sub_expl = True\n",
    "prefix = 'expl' if use_sub_expl == False else 'sub-expl' if use_sub_expl == True else 'grade'\n",
    "ylbl = 'Explanation' if use_sub_expl == False else 'Sub-Explanation' if use_sub_expl == True else 'Gleason Pattern'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "distr_in_path = in_path / \"class_dist\"\n",
    "if not (distr_in_path / \"sub-expl_label.npy\").exists():\n",
    "    for usage in [True, False, None]:\n",
    "        get_class_cooccurrence_between_labelers(dataset.df, usage, True, in_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr_in_path = in_path / \"class_dist\"\n",
    "assert os.path.exists(distr_in_path)\n",
    "\n",
    "grade_lbl = np.load(distr_in_path / \"grade_label.npy\")\n",
    "grade_val = np.load(distr_in_path / \"grade_value.npy\")\n",
    "\n",
    "grade_lbl = [\"Gleason Pattern \" + c_lbl for c_lbl in grade_lbl]\n",
    "\n",
    "expl_lbl = np.load(distr_in_path / \"sub-expl_label.npy\")\n",
    "expl_val = np.load(distr_in_path / \"sub-expl_value.npy\")\n",
    "\n",
    "grouped_lbl =np.load(distr_in_path / \"expl_label.npy\")\n",
    "grouped_val = np.load(distr_in_path / \"expl_value.npy\")\n",
    "\n",
    "# cmap = 'Blues'#{'3':'forestgreen', '4': 'royalblue', '5': 'firebrick'}\n",
    "# cmap_raw = 'Blues'#{i: \"forestgreen\" if i < 8 else \"royalblue\" if i < 25 else 'firebrick' for i in range(0, len(expl_lbl))} \n",
    "# cmap_grouped = 'Blues'#{i: \"forestgreen\" if i < 2 else \"royalblue\" if i < 5 else 'firebrick' for i in range(0, len(grouped_lbl))} \n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "ybar_fontsize = 19\n",
    "single_fontsize = 22\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 5), width_ratios=[0.09, 0.91])\n",
    "ax1.grid(axis='y', linestyle='--', linewidth=0.5, color='lightgray')\n",
    "ax1.tick_params(axis='y', labelsize=single_fontsize)\n",
    "ax1.set_ylim((0,900))\n",
    "\n",
    "ax2.grid(axis='y', linestyle='--', linewidth=0.5, color='lightgray')\n",
    "ax2.tick_params(axis='y', labelsize=single_fontsize)\n",
    "ax2.set_ylim((0,900))\n",
    "\n",
    "bar_width = 0.5\n",
    "bar_spacing = 0.1\n",
    "positions_grade = np.arange(len(grade_lbl)) * (bar_width + bar_spacing)\n",
    "positions_expl = np.arange(len(expl_lbl)) * (bar_width + bar_spacing)\n",
    "\n",
    "bars1 = ax1.bar(positions_grade, grade_val, width=0.3, color='#77b5d9')#[cmap[cat] for cat in grade_lbl])\n",
    "ax1.set_xticks(positions_grade)\n",
    "ax1.set_xticklabels(grade_lbl, fontsize=single_fontsize, rotation=45)\n",
    "\n",
    "bars2 = ax2.bar(positions_expl, expl_val, width=0.3, color='#77b5d9')#[cmap_raw[i] for i in range(len(expl_lbl))])\n",
    "ax2.set_xticks(positions_expl)\n",
    "ax2.set_xticklabels(expl_lbl, fontsize=single_fontsize, rotation=45)\n",
    "\n",
    "\n",
    "for bar, value in zip(bars1, grade_val):\n",
    "    ax1.text(bar.get_x() + bar.get_width() / 2, value + 0.5, str(value), ha='center', va='bottom', color='black', fontsize=ybar_fontsize)\n",
    "for bar, value in zip(bars2, expl_val):\n",
    "    ax2.text(bar.get_x() + bar.get_width() / 2, value + 0.5, str(value), ha='center', va='bottom', color='black', fontsize=ybar_fontsize)\n",
    "\n",
    "\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / \"class_dist_grade_expl.svg\", dpi=1000)\n",
    "plt.cla()\n",
    "plt.close()\n",
    "\n",
    "plt.rcParams['ytick.labelsize'] = single_fontsize\n",
    "\n",
    "plt.figure(figsize=(8, 7))\n",
    "plt.ylim((0,900))\n",
    "plt.grid(axis='y', linestyle='--', linewidth=0.5, color='lightgray')\n",
    "\n",
    "positions_grouped = np.arange(len(grouped_lbl)) * (bar_width + bar_spacing)\n",
    "\n",
    "bars = plt.bar(positions_grouped, grouped_val, width=0.3, color='#77b5d9')#[cmap_grouped[i] for i in range(len(grouped_lbl))])\n",
    "\n",
    "plt.xticks(positions_grouped, grouped_lbl, rotation=45, ha='right', fontsize=single_fontsize)\n",
    "plt.yticks(fontsize=single_fontsize)\n",
    "plt.grid(axis='y', linestyle='--', linewidth=0.5, color='lightgray')\n",
    "\n",
    "# Add y value labels at the bottom of each bar\n",
    "for bar, value in zip(bars, grouped_val):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, value + 0.5, str(value), ha='center', va='bottom', color='black', fontsize=ybar_fontsize)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / \"class_dist_explanation.svg\", dpi=1000)\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mac = Dice(num_classes=num_classes, average=\"macro\")\n",
    "d_mic = Dice(num_classes=num_classes, average=\"micro\")\n",
    "l = JDTLoss(alpha=0.5, beta=0.5)\n",
    "\n",
    "# Compute SoftDice C,D,I\n",
    "l_C = JDTLoss(mIoUC=1.0, mIoUD=0.0, mIoUI=0.0, alpha=0.5, beta=0.5, active_classes_mode_soft=\"ALL\")\n",
    "l_D = JDTLoss(mIoUC=0.0, mIoUD=1.0, mIoUI=0.0, alpha=0.5, beta=0.5, active_classes_mode_soft=\"ALL\")\n",
    "l_I = JDTLoss(mIoUC=0.0, mIoUD=0.9, mIoUI=1.0, alpha=0.5, beta=0.5, active_classes_mode_soft=\"ALL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emd = []\n",
    "for i in range(len(preds_ensemble)):#preds_ensemble.shape[0]):\n",
    "    rel_pred = preds_ensemble[i]\n",
    "    rel_bg = bgs[i]\n",
    "    rel_label = labels[i]\n",
    "\n",
    "    emd.append(((rel_pred[:, ~rel_bg] - rel_label[:, ~rel_bg]).abs().sum(dim=1)/2)/(~rel_bg).sum())\n",
    "\n",
    "emd = torch.stack(emd).mean(dim=0)\n",
    "print(emd)\n",
    "emd.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl = torchmetrics.KLDivergence()\n",
    "kls = []\n",
    "\n",
    "for i in range(len(preds_ensemble)):#preds_ensemble.shape[0]):\n",
    "    rel_pred = preds_ensemble[i]\n",
    "    rel_bg = bgs[i]\n",
    "    rel_label = labels[i]\n",
    "\n",
    "    rel_pred = rel_pred[:, ~rel_bg]\n",
    "    rel_label = rel_label[:, ~rel_bg]\n",
    "\n",
    "    kls.append(torch.nn.functional.kl_div(torch.log(rel_pred).unsqueeze(0), rel_label.unsqueeze(0)))\n",
    "\n",
    "kls\n",
    "torch.mean(torch.stack(kls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tverskys = []\n",
    "active_classes = []\n",
    "per_image_dice_scores = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    bg = bgs[i]\n",
    "    label = labels[i]\n",
    "\n",
    "    tversky, ac = l.get_image_class_matrix(preds_ensemble[i][:, ~bg].unsqueeze(0), labels[i][:, ~bg].unsqueeze(0), prob_predictions=True)\n",
    "    tverskys.append(tversky)\n",
    "    active_classes.append(ac)\n",
    "\n",
    "    # Find parts of label with non-unique maximum\n",
    "    label_max = torch.max(label, dim=0)[0]\n",
    "    duplicated_max = torch.sum(label == label_max.unsqueeze(0), dim=0) > 1\n",
    "\n",
    "    unique_max = ~duplicated_max\n",
    "    fg = ~bg\n",
    "\n",
    "    unique_max_fg = torch.logical_and(fg, unique_max)\n",
    "    per_image_dice_scores.append(torchmetrics.functional.dice(preds_ensemble[i][:, unique_max_fg].unsqueeze(0).argmax(dim=1), labels[i][:, unique_max_fg].unsqueeze(0).argmax(dim=1), average=\"none\", num_classes=num_classes))\n",
    "    d_mac.update(preds_ensemble[i][:, unique_max_fg].unsqueeze(0).argmax(dim=1), labels[i][:, unique_max_fg].unsqueeze(0).argmax(dim=1))\n",
    "    d_mic.update(preds_ensemble[i][:, unique_max_fg].unsqueeze(0).argmax(dim=1), labels[i][:, unique_max_fg].unsqueeze(0).argmax(dim=1))\n",
    "tverskys = torch.stack(tverskys).squeeze()\n",
    "active_classes = torch.stack(active_classes).squeeze()\n",
    "per_image_class_dice_scores = torch.stack(per_image_dice_scores).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(per_image_class_dice_scores.nanmean(dim=0).mean(),d_mac.compute(), d_mic.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IoUCs = []\n",
    "for c in range(num_classes):\n",
    "    if active_classes[:, c].sum() > 0:\n",
    "        IoUCs.append(tverskys[:, c][active_classes[:, c]].mean())\n",
    "\n",
    "mIoUC = torch.sum(torch.stack(IoUCs)) / (active_classes.sum(dim=0) > 0).sum()\n",
    "mIoUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IoUIs = []\n",
    "for i in range(tverskys.shape[0]):\n",
    "    IoUIs.append(tverskys[i, :][active_classes[i, :]].mean())\n",
    "\n",
    "mIoUI = torch.sum(torch.stack(IoUIs)) / tverskys.shape[0]\n",
    "mIoUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mac_dice = SoftDICEMetric(average=\"macro\")\n",
    "other_soft_dice = SoftCorrectDICEMetric(average=None)\n",
    "\n",
    "for i in range(len(preds_ensemble)):#preds_ensemble.shape[0]):\n",
    "    rel_pred = preds_ensemble[i]\n",
    "    rel_bg = bgs[i]\n",
    "    rel_label = labels[i]\n",
    "\n",
    "    rel_pred = rel_pred[:, ~rel_bg]\n",
    "    rel_label = rel_label[:, ~rel_bg]\n",
    "\n",
    "    my_mac_dice.update(rel_pred, rel_label)\n",
    "    other_soft_dice.update(rel_pred.unsqueeze(0), rel_label.unsqueeze(0))\n",
    "\n",
    "print(my_mac_dice.compute())\n",
    "print(other_soft_dice.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confm_ml = conf_matrix.compute()\n",
    "confm_ml_reshape = confm_ml.reshape(confm_ml.shape[0], -1)\n",
    "num_pixels = confm_ml_reshape.sum(dim=1)\n",
    "confm_ml_reshape_normed = confm_ml_reshape / num_pixels.reshape(-1, 1)\n",
    "\n",
    "TN, FP, FN, TP = confm_ml_reshape[:, 0], confm_ml_reshape[:, 1], confm_ml_reshape[:, 2], confm_ml_reshape[:, 3]\n",
    "\n",
    "P = (TP+FN)\n",
    "N = (TN+FP)\n",
    "\n",
    "POPU = (TN+FP+FN+TP)\n",
    "ACC = (TN+TP)/POPU\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = (TN/(TN+FP))\n",
    "PREC = TP/(FP+TP)\n",
    "BACC = (TPR+TNR) / 2\n",
    "DICE = (2*TP)/(2*TP+FP+FN)\n",
    "\n",
    "PREL = P / POPU\n",
    "\n",
    "confm_ml_reshape_normed = torch.cat([PREL.reshape(num_classes, 1), confm_ml_reshape_normed[:, [3,0,1,2]], ACC.reshape(\n",
    "    num_classes, 1), PREC.reshape(num_classes, 1), BACC.reshape(num_classes, 1), DICE.reshape(num_classes,1)], dim=1)\n",
    "\n",
    "im3 = plt.matshow(confm_ml_reshape_normed)\n",
    "plt.colorbar(im3)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6, 7,8], [\"PREL\", \"TP\", \"TN\", \"FP\", \"FN\", \"ACC\", \"PREC\", \"BA\", \"DICE\"], rotation=45)\n",
    "_ = plt.yticks(range(len(classes_named)), classes_named)\n",
    "_ = plt.xlabel(\"Metrics in %\")\n",
    "for (i, j), val in np.ndenumerate(confm_ml_reshape_normed):\n",
    "    plt.text(j, i, f\"{val*1000:0.0f}\",c=\"red\", ha=\"center\", va=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@wid.interact(idx=wid.IntSlider(min=0, max=len(data)-1, value=0))\n",
    "def show_worst_results(idx):\n",
    "    _ = create_single_class_acti_maps(predictions=preds_ensemble, dataset=data, idx=idx, plot_mode=\"heatmap\", strip_background=True)\n",
    "    # _ = create_ensemble_plot(dataset=data, ensemble_predictions=preds_ensemble, individual_predictions=preds, idx=idcs[idx], show_ensemble_preds=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idcs = [4, 16, 22, 25, 29, 30, 35, 52, 53, 54, 84, 90, 113, 114, 142]\n",
    "interest_cases = [ 85, 79, 105]\n",
    "bad_cases =[66,83]\n",
    "57,108, 133, 151\n",
    "final_preds = [57,108,54, 4, 84, 85, 105, 66, 83]\n",
    "\n",
    "create_multi_seg_anno_plot(predictions=preds, dataset=data, idcs=final_preds, strip_background=True, legend=True, class_names=class_names)\n",
    "plt.savefig(fig_dir / \"imgs_final_paper.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, idcs = torch.sort(torch.stack(IoUIs), descending=True)\n",
    "\n",
    "@wid.interact(idx=wid.IntSlider(min=0, max=len(data)-1, value=0))\n",
    "def show_worst_results(idx):\n",
    "    _ = create_single_class_acti_maps(predictions=preds_ensemble, dataset=data, idx=idcs[idx], plot_mode=\"heatmap\", strip_background=True)\n",
    "    #_ = create_ensemble_plot(dataset=data, ensemble_predictions=preds_ensemble, individual_predictions=preds, idx=idcs[idx], show_ensemble_preds=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, idcs = torch.sort(torch.stack(IoUIs), descending=True)\n",
    "\n",
    "import ipywidgets as wid\n",
    "\n",
    "def show_worst_results(idx):\n",
    "    f, ax = create_single_class_acti_maps(predictions=preds_ensemble, dataset=data, idx=idcs[20], plot_mode=\"heatmap\", strip_background=True, plot=False)\n",
    "    plt.subplots_adjust\n",
    "    plt.savefig(\"./figures/test.png\", dpi=2000)\n",
    "    #_ = create_ensemble_plot(dataset=data, ensemble_predictions=preds_ensemble, individual_predictions=preds, idx=idcs[idx], show_ensemble_preds=0)\n",
    "\n",
    "show_worst_results(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals, idcs = torch.sort(torch.stack(IoUIs), descending=True)\n",
    "imgs_good = np.array([3,5,6,9,10,11,14,15,16,18,20,21,23,24,34,36,45,46,92])\n",
    "sm_plot = np.array([25,46])\n",
    "\n",
    "sieht_anders = np.array([49, 56, 58, 70, 63, 91, 17])\n",
    "\n",
    "ganz_anders =np.array([62,68,73, 26])\n",
    "\n",
    "#fs = []\n",
    "#axess =[]\n",
    "#for idx in imgs_good:\n",
    "#    create_simple_seg_anno_plot(predictions=preds_ensemble, dataset=data, idx=idcs[idx], plot_mode=\"heatmap\", strip_background=True, plot=True)\n",
    "\n",
    "create_multi_seg_anno_plot(predictions=preds_ensemble, dataset=data, idcs=[idcs[i] for i in sm_plot], strip_background=True)\n",
    "plt.savefig(\"./figures/imgs_good.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vis = np.concatenate([imgs_good[[2,5,7,8,16]], sieht_anders[[2,6]], ganz_anders[[0,3]]], axis=0)\n",
    "create_multi_seg_anno_plot(predictions=preds_ensemble, dataset=data, idcs=[idcs[i] for i in to_vis], strip_background=True)\n",
    "plt.savefig(\"./figures/imgs_good_selected.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_good[[2,5,7,8,16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_pathos = ConfusionMatrix(task=\"multiclass\", num_classes=10)\n",
    "cm_net = ConfusionMatrix(task=\"multiclass\", num_classes=10)\n",
    "\n",
    "from itertools import combinations\n",
    "for i in range(len(data)):\n",
    "    (_, patho_preds, bg) = data.__getitem__(i, False)\n",
    "\n",
    "    pred = preds[i].squeeze(0).argmax(dim=0)[~bg]\n",
    "\n",
    "\n",
    "\n",
    "    for a,b in combinations(patho_preds, r=2):\n",
    "        a = torch.tensor(a[~bg])\n",
    "        b = torch.tensor(b[~bg])\n",
    "        cm_pathos.update(a,b)\n",
    "        cm_pathos.update(b,a)\n",
    "\n",
    "    for patho_pred in patho_preds:\n",
    "        patho_pred = torch.tensor(patho_pred[~bg])\n",
    "        cm_net.update(pred,patho_pred)\n",
    "        cm_net.update(patho_pred,pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_results1 = cm_pathos.compute().numpy()\n",
    "cm_results1 = cm_results1 / cm_results1.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "sns.heatmap(cm_results1*1000, xticklabels=class_names, yticklabels=class_names, fmt=\".0f\", cmap=\"Blues\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_results2 = cm_net.compute().numpy()\n",
    "cm_results2 = cm_results2 / cm_results2.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "sns.heatmap(cm_results2*1000, xticklabels=class_names, yticklabels=class_names, fmt=\".0f\", cmap=\"Blues\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap((cm_results2-cm_results1)*1000, xticklabels=class_names, yticklabels=class_names, fmt=\".0f\", cmap=\"bwr\", annot=True, vmin=-200, vmax=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_pathos.compute().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm_net_results = cm_pathos.compute().numpy()\n",
    "\n",
    "cm_net_results = cm_net_results / cm_net_results.sum(axis=1).reshape(-1,1)\n",
    "plt.matshow(cm_pathos.compute().numpy())\n",
    "plt.xticks(range(10), class_names, rotation=45, ha=\"left\")\n",
    "plt.yticks(range(10), class_names, rotation=45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalGleasonXAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
