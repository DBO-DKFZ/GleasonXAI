# Gleason XAI:

Paper: [arxiv](https://doi.org/10.48550/arXiv.2410.15012)
---
## System Requirements
Software dependencies can be found in the `conda-env.yml`.

The Software was created and tested on a Linux system with a GPU.

## Use
### General set up:
1. Create and activate conda environment using the conda_env.yml with
   ```
   conda env create -f path/to/conda_env.yml
   conda activate GleasonXAI
   ```

2. If you either plan to train a model or want to generate the visualizations of the paper, install [pytorch with cuda support (12.1)](https://pytorch.org/get-started/locally/) i.e. for Linux:
   ```
   pip install torch torchvision torchaudio -I --index-url https://download.pytorch.org/whl/cu121 
   ```

3. Set environment variables:
   - `DATASET_LOCATION`: location of the images and the dataframe containing the labels
   - `EXPERIMENT_LOCATION`: location for the log files during experiments 

4. Download accompaning `data_and_code` from figshare. You should receive a `GleasonXAI_data.zip`.

5. [setup.py](setup.py) has default values for the download links for the Gleason2019. If they work you need to do nothing (see next step). If you encounter an error in the next step, generate download links for the [Gleason 2019 challenge data](https://gleason2019.grand-challenge.org/Register/) (test and training sets) by copying the link generated by clicking on "Download all" on their sync download page. Alternatively, download the datasets. 

6. use [setup.py](setup.py) to create the data structure as needed (see below).

    |     parameter     |  type  |                             use                             |
    |:-----------------:|:------:|:-----------------------------------------------------------:|
    | --gleasonxai_data | string | path to directory / zip file containing the dowloaded data (`GleasonXAI_data.zip`) |
    | --manual_xai_data | flag   | if set: expect GleasonXAI data to already be in expected structure and place|
    | --download        | flag   | if set: download / unzip datasets and copy to expected path   |
    | --calibrate       | flag   | if set: create micron/pixel calibrated images                 |
    | --gleason19_test  | string | Download link to the Gleason 2019 challenge test set *        |
    | --gleason19_train | string | Download link to the Gleason 2019 challenge training set *    |
    | --arvaniti        | string | Download link to the Harvard Arvaniti et al. data set (has a default value, that should work).         |

<div align="center">
 * or path to downloaded zip file containing the test / train images
</div>

<br>

This creates the following expected directory structure (depending on set flags):

```bash
├── [DATASET_LOCATION]
│   └── GleasonXAI
│       ├── final_filtered_explanations_df.csv
│       ├── label_remapping.json
│       ├── TMA
│       │    ├── original
│       │    │    ├── PR482a_A1.jpg
│       │    │    ├── PR482a_A2.jpg
│       │    │    └── ...
│       │    └── MicronsCalibrated
│       │         ├── PR482a_A1.jpg
│       │         ├── PR482a_A2.jpg
│       │         └── ...
│       └── GleasonFinal2
│            └── label_level1
│                 ├── SoftDiceBalanced-1
│                 │   └── version_0
│                 │       └── checkpoints
│                 │           └── best_model.ckpt
│                 ├── SoftDiceBalanced-2
│                 │   └── version_0
│                 │       └── checkpoints
│                 │           └── best_model.ckpt
│                 └── SoftDiceBalanced-3
│                     └── version_0
│                         └── checkpoints
│                             └── best_model.ckpt
└── ...
```

<br>
<br>


---  


### Image predictions:

1. call [setup.py](setup.py) with `gleasonxai_data` set to unpack the model weights  
   i.e.:
   ```
   python setup.py --gleasonxai_data "/path/to/GleasonXAI_data.zip"
   ```

2. call [run_gleasonXAI.py](run_gleasonXAI.py) with the following parameters:

    |     parameter     |  type  |                             use                             |
    |:-----------------:|:------:|:-----------------------------------------------------------:|
    | --images                 | string | path to images to make predictions on (single image or directory) |
    | --checkpoint_absolute    | flag   | if set: checkpoint paths are absolute paths, else assumed relative to DATASET_LOCATION |
    | --checkpoint_1           | string | path to first of three GleasonXAI models                  |
    | --checkpoint_2           | string | path to second of three GleasonXAI models                  |
    | --checkpoint_3           | string | path to third of three GleasonXAI models                  |  
    | --save_path              | string | path to output directory                                  |


    The default values for the checkpoints are set to the paths setup.py will move the model weigths to. 
    It the setup was done with the setup.py, call:
     ```
    python run_gleasonXAI.py --images "/path/to/imagedir" --save_path "/path/to/outputdir"
    ```
<br>
<br>

---

### Paper Visualizations:

1. call [setup.py](setup.py) with `gleasonxai_data`, `download` and `calibrate` set and provide paths or urls to Gleason 2019 challenge data   
   i.e.:
   ```
   python setup.py --gleasonxai_data "/path/to/GleasonXAI_data.zip" --download --calibrate --gleason19_train "/path/to/Train Imgs.zip" --gleason19_test "/path/to/Test.zip"
   ```

2. run [test.py](test.py) to create predictions on the test set  
   (at least for models in `GleasonFinal2/label_level1/SoftDiceBalanced-{i}/version_0/`).


    |     parameter     |  type  |                             use                             |
    |:-----------------:|:------:|:-----------------------------------------------------------:|
    | --experiment_path | string | path to directory containing all model weights and settings |
    | --checkpoint      | string | path within experiment_path to search for models and settings in |
    | --glob_checkpoints| string | Regex to select models trained with specified loss only          |
  
    If the setup.py was used, the following call can be done to generate the predictions for the GleasonXAI:
     ```
     python test.py --experiment_path "/[DATASET_LOCATION]/GleasonXAI" --checkpoint "GleasonFinal2/label_level1" --glob_checkpoints "SoftDiceBalanced-*"
     ```

3. open and run the jupyter notebook [evaluate_paper_results.ipynb](evaluate_paper_results.ipynb) to create the visualizations and figures of the paper.

<br>
<br>

---

## Model training

1. call [setup.py](setup.py) with `gleasonxai_data`, `download` and `calibrate` set and provide paths or urls to Gleason 2019 challenge data if needed   
   i.e.:
   ```
   python setup.py --gleasonxai_data "/path/to/GleasonXAI_data.zip" --download --calibrate --gleason19_train "/path/to/Train Imgs.zip" --gleason19_test "/path/to/Test.zip"
   ```

2. Use the provided configs in [/configs/](/configs/) to set all hyperparameters and loss functions. Our project uses the [hydra](https://hydra.cc/) framework to parse the tree of configs and configure your training.


3. call [run_training.py](run_training.py)

Example configurations:

* SoftDiceLoss on soft label explanations: 
  ```
  run_training.py dataset.label_level=1 loss_functions=soft_dice_balanced experiment=EXPERIMENTNAME/CAN/CONTAIN/SUBFOLDERS
  ```

* DICELoss on majority voted explanations: 
  ```
  run_training.py dataset.label_level=1 loss_functions=dice_loss experiment=YOUREXPERIMENTNAME
  ```

When setting dataset.label_level to 0, you can directly train on Gleason patterns (label_level=2 are the sub-explanations).