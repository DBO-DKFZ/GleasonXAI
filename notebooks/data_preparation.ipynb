{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plainsight data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_ZPX_U-B23TF"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import pprint\n",
        "import statistics\n",
        "import typing\n",
        "\n",
        "from pathlib import Path\n",
        "from itertools import chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WHFxM5TbwgTp"
      },
      "outputs": [],
      "source": [
        "base_source = Path('/Users/c140-admin/Documents/03 Gleason/raw_data') # base directory for raw data\n",
        "data_source = base_source / 'explanation_annotations (Plainsight raw data)' # directory containing the Plainsight data\n",
        "img_source = Path('/Users/c140-admin/Documents/03 Gleason/data') # image and additional file source directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIkK71DerraE"
      },
      "source": [
        "### Annotation cleaning methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ySoJkP0xrqcv"
      },
      "outputs": [],
      "source": [
        "def group_bfill(group):\n",
        "    return group.bfill()\n",
        "\n",
        "def group_ffill(group):\n",
        "    return group.ffill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F0tpdvruzD9w"
      },
      "outputs": [],
      "source": [
        "def get_annotator_group(annotator_folder_name):\n",
        "  annotator_group = annotator_folder_name.split('_')[-3:]\n",
        "  if annotator_group[0] == 'E':\n",
        "    annotator_group = '.'.join(annotator_group[1:])\n",
        "  elif not annotator_group[1].isnumeric():\n",
        "    annotator_group = annotator_group[2]\n",
        "  elif not annotator_group[2].isnumeric():\n",
        "    annotator_group = '.'.join(annotator_group)\n",
        "  else:\n",
        "    annotator_group = ('.').join(annotator_group[1:])\n",
        "  return annotator_group\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jiVFHDPxzXq7"
      },
      "outputs": [],
      "source": [
        "def get_annotations_and_coords(annotations, annotator):\n",
        "  comment_exists = False\n",
        "\n",
        "  # initialise the dataframes\n",
        "  explanations_df = pd.DataFrame(columns = [\"annotator\", \"TMA\", \"grade\", \"coords\", \"explanations\", \"group\"])\n",
        "  comments_df = pd.DataFrame(columns = [\"annotator\", \"TMA\", \"grade\", \"comments\"])\n",
        "\n",
        "  num_TMAs = len(annotations[annotator]['labels'])\n",
        "\n",
        "  annotator_group = get_annotator_group(annotator)\n",
        "\n",
        "\n",
        "  # iterate over each TMA the annotator worked on\n",
        "  for TMA_index in range(num_TMAs):\n",
        "\n",
        "      TMA_name = annotations[annotator]['labels'][TMA_index]['dataId'][:-5]\n",
        "      base_path_to_data = annotations[annotator]['labels'][TMA_index][\"annotations\"]\n",
        "      grades = list(base_path_to_data.keys())\n",
        "\n",
        "      # iterate over each possible grade per TMA (3, 4 and 5)\n",
        "      for grade in grades:\n",
        "          if grade in base_path_to_data:\n",
        "              # determine the number of explanation polygons in the grade and iterate over them\n",
        "              num_polygons = len(base_path_to_data[grade])\n",
        "              for i in range(num_polygons):\n",
        "                  # flag to keep track whether a textual explanation was chosen\n",
        "                  text_exists = False\n",
        "\n",
        "                  # retrieve the polygon coordinates\n",
        "                  polygon_coords = base_path_to_data[grade][i][\"data\"][\"points\"]\n",
        "                  explanation_keys = base_path_to_data[grade][i][\"children\"].keys()\n",
        "                  \n",
        "                  # retrieve the textual explanations\n",
        "                  for key in explanation_keys:\n",
        "\n",
        "                      path_to_textual_explanations = base_path_to_data[grade][i][\"children\"][key][\"data\"]\n",
        "\n",
        "                      # check if there is an additional comment\n",
        "                      if type(path_to_textual_explanations)==str:\n",
        "                          comments_row = [annotator, TMA_name, grade, path_to_textual_explanations]\n",
        "                          comments_df.loc[len(comments_df)] = comments_row\n",
        "                          comment = path_to_textual_explanations\n",
        "                          if not comment == \"\":\n",
        "                              comment_exists = True\n",
        "                      # if only none (which is the default value) it is empty\n",
        "                      else:\n",
        "                          if path_to_textual_explanations['selected'] in [['none'], 'none', [], ['Bitte wählen Sie eine passende Erklärung aus.']]:\n",
        "                              continue\n",
        "                          else:\n",
        "                              text_exists = True\n",
        "                              valid_key = key\n",
        "                              textual_explanation = path_to_textual_explanations['selected']\n",
        "\n",
        "                              # clean the textual explanations\n",
        "                              if type(textual_explanation)==list and \"none\" in textual_explanation:\n",
        "                                  textual_explanation.remove(\"none\")\n",
        "                              if type(textual_explanation)==list and \"Bitte wählen Sie eine passende Erklärung aus.\" in textual_explanation:\n",
        "                                  textual_explanation.remove(\"Bitte wählen Sie eine passende Erklärung aus.\")\n",
        "                              if type(textual_explanation)==list and \"Bitte wählen Sie mindestens eine Erklärung aus.\" in textual_explanation:\n",
        "                                  textual_explanation.remove(\"Bitte wählen Sie mindestens eine Erklärung aus.\")\n",
        "                              if path_to_textual_explanations['selected'] in [['none'], 'none', [], ['Bitte wählen Sie eine passende Erklärung aus.']]:\n",
        "                                  continue\n",
        "\n",
        "                              if valid_key not in ['Andere Erklärung', 'Erklärungen Gleason Grad 3',\n",
        "                                                   'Erklärungen Gleason Grad 4', 'Erklärung Gleason Grad 5',\n",
        "                                                   \"Erklärungen Gleason 3\", \"Erklärungen Gleason 4\",\n",
        "                                                   \"Erklärungen Gleason 5\", \"Erklärung Gleason 5\", \"Erklärung\",\n",
        "                                                  \"Erklärung Gleason 4\", \"Erklärungen\", \"Explanation for Gleason 3\",\n",
        "                                                  \"Another explanation\", \"Explanation for Gleason 4\", \"Explanation for Gleason 5\",\n",
        "                                                  \"Explanation Gleason 5\", \"Explanations for Gleason 3\",\n",
        "                                                  \"Explanation  for Gleason 5\", \"Explanations Gleason 3\",\n",
        "                                                  \"Explanations Gleason 4\", \"Explanations Gleason 5\", \"Explanation Gleason 4\",\n",
        "                                                  \"Explanation Gleason 3\", \"Explanations gleason 3\", \"Explanations gleason 4\",\n",
        "                                                  \"Explanations gleason 5\", \"Explanation gleason 5\", \"Explanations Glaason 4\"]:\n",
        "                                  if type(textual_explanation)==list:\n",
        "                                      textual_explanation = valid_key + \" \" + textual_explanation[0]\n",
        "                                  else:\n",
        "                                      textual_explanation = valid_key + \" \" + textual_explanation\n",
        "                              else:\n",
        "                                  if type(textual_explanation)==list:\n",
        "                                      textual_explanation = textual_explanation[0]\n",
        "\n",
        "                          # more cleaning\n",
        "                          if textual_explanation == \"Bitte wählen Sie mindestens eine Erklärung aus.\":\n",
        "                              textual_explanation = \"No textual explanation given\"\n",
        "                          if textual_explanation.endswith(\"Bitte wählen Sie mindestens eine Erklärung aus.\"):\n",
        "                              textual_explanation = textual_explanation[:-len(\"Bitte wählen Sie mindestens eine Erklärung aus.\")].strip()\n",
        "                          if textual_explanation.endswith(\" Bitte wählen Sie eine p\"):\n",
        "                              textual_explanation = textual_explanation[:-len(\" Bitte wählen Sie eine p\")].strip()\n",
        "                          if textual_explanation.endswith(\" Bitte wählen Sie eine passende Erklärung aus.\"):\n",
        "                              textual_explanation = textual_explanation[:-len(\" Bitte wählen Sie eine passende Erklärung aus.\")].strip()\n",
        "                          if textual_explanation.endswith(\" none\"):\n",
        "                              textual_explanation = textual_explanation[:-len(\"none\")].strip()\n",
        "                          if textual_explanation == \"\":\n",
        "                              textual_explanation = \"No textual explanation given\"\n",
        "                          if textual_explanation == []:\n",
        "                              textual_explanation = \"No textual explanation given\"\n",
        "\n",
        "                          # if there is both an explanation and a comment, put them together\n",
        "                          if comment_exists:\n",
        "                              textual_explanation = textual_explanation + \".\\n Free text: \" + comment\n",
        "\n",
        "                          # add the polygon and explanation data to the dataframe\n",
        "                          row = [annotator, TMA_name, grade, polygon_coords, textual_explanation, annotator_group]\n",
        "                          explanations_df.loc[len(explanations_df)] = row\n",
        "\n",
        "                  # handle the case of no textual explanation chosen\n",
        "                  if not text_exists:\n",
        "                      if comment_exists:\n",
        "                          textual_explanation = \"Free text: \" + comment\n",
        "                      else:\n",
        "                          textual_explanation = \"No textual explanation given\"\n",
        "                      row = [annotator, TMA_name, grade, polygon_coords, textual_explanation, annotator_group]\n",
        "                      explanations_df.loc[len(explanations_df)] = row\n",
        "\n",
        "                  # set the comment flag back\n",
        "                  comment_exists = False\n",
        "  return explanations_df, comments_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENUpVC5xr3kn"
      },
      "source": [
        "## Export Test & Validation Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(img_source / \"label_remapping.json\", \"r\") as f:\n",
        "        label_mapping = json.load(f)\n",
        "\n",
        "with open(img_source / \"free_text_mapping.json\", \"r\") as f:  \n",
        "        free_text_mapping = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_ranks = [\"variable sized well-formed individual and discrete glands\",\n",
        "                                \"compressed or angular discrete glands\",\n",
        "                                \"poorly formed and fused glands\",\n",
        "                                \"Cribriform glands\",\n",
        "                                \"Glomeruloid glands\",\n",
        "                                \"solid groups of tumor cells\",\n",
        "                                \"cords\",\n",
        "                                \"single cells\",\n",
        "                                \"presence of comedonecrosis\",]\n",
        "label_grade = {\"variable sized well-formed individual and discrete glands\": 3,\n",
        "                                \"compressed or angular discrete glands\": 3,\n",
        "                                \"poorly formed and fused glands\": 4,\n",
        "                                \"Cribriform glands\": 4,\n",
        "                                \"Glomeruloid glands\": 4,\n",
        "                                \"solid groups of tumor cells\": 5,\n",
        "                                \"cords\": 5,\n",
        "                                \"single cells\": 5,\n",
        "                                \"presence of comedonecrosis\": 5,}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_explanation(remap_label, language):\n",
        "    # Helper function to split the explanation in our actual given explanation and the free text.\n",
        "    # Further removes errors of the explanation string for example new lines, double spaces etc.\n",
        "\n",
        "    def split_explanations(input_string):\n",
        "        chars_to_strip = \" .\\n\\r\"\n",
        "\n",
        "        if pd.notna(input_string):\n",
        "            input_string = input_string.replace(\"\\n\", \"\")\n",
        "            input_string = input_string.replace(\"\\r\", \"\")\n",
        "            input_string = input_string.replace(\n",
        "                \"  \", \" \")  # Replace double whitespace\n",
        "\n",
        "            if \"Free text:\" in input_string:\n",
        "                parts = input_string.split('Free text:', 1)\n",
        "                text_before = parts[0].strip(chars_to_strip)\n",
        "                text_after = parts[1].strip(chars_to_strip)\n",
        "                if text_before == \"\":\n",
        "                    text_before = np.nan\n",
        "            else:\n",
        "                text_before = input_string.strip(chars_to_strip)\n",
        "                text_after = np.nan\n",
        "\n",
        "            if pd.notna(text_before):\n",
        "                text_before = text_before.strip(chars_to_strip)\n",
        "                text_before = text_before.lower()\n",
        "\n",
        "            if pd.notna(text_after):\n",
        "                text_after = text_after.strip(chars_to_strip)\n",
        "                text_after = text_after.lower()\n",
        "\n",
        "            return text_before, text_after\n",
        "        else:\n",
        "            return np.nan, np.nan\n",
        "\n",
        "    expl, freetext = split_explanations(remap_label)\n",
        "\n",
        "    remap_of_labels_german = label_mapping[\"german_errors\"]\n",
        "    remap_of_labels_english = label_mapping[\"english_errors\"]\n",
        "    german_to_english_map = label_mapping[\"translated\"]\n",
        "    label_hierarchy = label_mapping[\"hierarchy\"]\n",
        "\n",
        "    if language:\n",
        "        if expl in remap_of_labels_english:\n",
        "            expl = remap_of_labels_english[expl]\n",
        "    else:\n",
        "        if expl in remap_of_labels_german:\n",
        "            expl = remap_of_labels_german[expl]\n",
        "        \n",
        "        if expl in german_to_english_map:\n",
        "            expl = german_to_english_map[expl]\n",
        "    \n",
        "    if freetext in free_text_mapping:\n",
        "        freetext = free_text_mapping[freetext]\n",
        "\n",
        "    if str(expl) == 'nan':\n",
        "        expl = freetext\n",
        "\n",
        "    # Get rid of Gleason levels\n",
        "    label_hierarchy = {new_exp: old_exp for _, gleason_grade_exps in label_hierarchy.items(\n",
        "    ) for new_exp, old_exp in gleason_grade_exps.items()}\n",
        "\n",
        "    label_hierachry_remapping = {}\n",
        "    for new_exp, old_exps in label_hierarchy.items():\n",
        "        for old_exp in old_exps:\n",
        "            label_hierachry_remapping[old_exp] = new_exp\n",
        "    \n",
        "    if expl in label_hierachry_remapping:\n",
        "        return label_hierachry_remapping[expl]\n",
        "    else:\n",
        "        print(\"expl not in mapping:\", expl)\n",
        "        print(\"maybe freetext:\", freetext)\n",
        "        return label_hierachry_remapping[freetext]\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_sorted(explanations: typing.List[str], english: bool):\n",
        "    ranks = []\n",
        "    for expl in explanations:\n",
        "        mapped_expl = clean_explanation(expl, english)\n",
        "        ranks.append(label_ranks.index(mapped_expl))\n",
        "        \n",
        "    exp_rank_pairs = list(zip(explanations, ranks))\n",
        "    sorted_exp = sorted(exp_rank_pairs, key=lambda x: x[1])\n",
        "    sorted_exp = [label for label,_ in sorted_exp]\n",
        "\n",
        "    return sorted_exp\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_double_as_df(df: pd.DataFrame, doubles_df: pd.DataFrame):\n",
        "    # df: full df to get imputed -> WILL BE CHANGED in method\n",
        "    # doubles_df: rows of the df which are multi-select polygons\n",
        "\n",
        "    extention_df = []\n",
        "    indices = []\n",
        "\n",
        "    doubles_df = doubles_df.astype(\"string\")\n",
        "    for _, group in doubles_df.groupby([\"coords\"]):\n",
        "        indices.append(group.index)\n",
        "    \n",
        "    annotator = df[\"annotator\"].unique()[0]\n",
        "    english = True if 'E' in annotator.split('_') else False\n",
        "    english = False if annotator == \"Karl_Karlson_E_3_5\" else english\n",
        "\n",
        "    for poly in indices: # for each multiselected polygon\n",
        "        explanations = []\n",
        "        for idx in poly:\n",
        "            explanations.append(df.iloc[idx]['explanations'])\n",
        "\n",
        "        sorted_explanations = get_sorted(explanations, english)\n",
        "\n",
        "        for num, idx in enumerate(poly):\n",
        "             df.at[idx, 'explanations'] = sorted_explanations[num]\n",
        "        \n",
        "        current_TMA = df.iloc[idx]['TMA']\n",
        "        \n",
        "        first_id = poly[0]\n",
        "        last_id = first_id\n",
        "        first_id -= 1\n",
        "        while df.iloc[first_id]['imputed'] == True and df.iloc[first_id]['TMA'] == current_TMA: # stay within TMA\n",
        "            first_id -= 1\n",
        "        first_id += 1\n",
        "\n",
        "        if first_id != last_id:\n",
        "            idx_adds = [i / len(explanations) for i in range(0, len(explanations))]\n",
        "            for i in range(first_id, last_id): # for each to impute\n",
        "                current_row = df.iloc[i]\n",
        "                df.at[i, 'explanations'] = sorted_explanations[0] # set the zeroth explanation\n",
        "\n",
        "                for j, expl_to_add in enumerate(sorted_explanations[1:]): # generate rows for the other explanations\n",
        "                    new_row = current_row.copy()\n",
        "                    new_row['explanations'] = expl_to_add\n",
        "                    new_row.name = int(new_row.name) + idx_adds[j+1] # set index of the rows to add so they are included after idx sort after original\n",
        "                    extention_df.append(new_row)\n",
        "    return extention_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVbnZPMQl6Gf",
        "outputId": "90f87df0-752e-461c-c3e7-190c3c720c53"
      },
      "outputs": [],
      "source": [
        "drop_annotator = ['first_half_Victoria_Victoriason_E_19_1', 'Ann_Annson_3_4', 'Joe_Joeson_E_3_2']\n",
        "\n",
        "def get_dfs(folder_name, file_names):\n",
        "  dupes = 0\n",
        "  collected_explanations = []\n",
        "\n",
        "  annotator = folder_name.name\n",
        "  if annotator in drop_annotator:\n",
        "    print(\"dropped:\", annotator)\n",
        "    return (pd.DataFrame([]), pd.DataFrame([]), pd.DataFrame([])), 0\n",
        "  \n",
        "  for fname in file_names:\n",
        "    t_file = folder_name / fname\n",
        "\n",
        "    with open(t_file, 'r') as data_file:\n",
        "      data = data_file.read()\n",
        "      json_data = json.loads(data)\n",
        "\n",
        "      annotations = {}\n",
        "      annotations[annotator] = json_data\n",
        "      explanations_df, _ = get_annotations_and_coords(annotations, annotator)\n",
        "\n",
        "      firsts = explanations_df[\"coords\"].duplicated(keep=\"first\")\n",
        "      duplicates = explanations_df[\"coords\"].duplicated(keep=False)\n",
        "\n",
        "      dupe_indices = explanations_df[firsts | duplicates].index\n",
        "      dupes += duplicates.sum()\n",
        "\n",
        "      explanations_df = explanations_df.replace(\"No textual explanation given\", np.nan)\n",
        "      explanations_df['imputed'] = explanations_df['explanations'].isna()\n",
        "      explanations_df[\"explanations\"] = explanations_df.groupby('TMA', group_keys=False)['explanations'].apply(group_bfill)\n",
        "\n",
        "      if len(dupe_indices) > 0:\n",
        "        print(\"before\", len(explanations_df))\n",
        "        cat_dfs = get_double_as_df(explanations_df, explanations_df[firsts | duplicates])\n",
        "\n",
        "        extention_df = pd.DataFrame(cat_dfs)\n",
        "        explanations_df = pd.concat([explanations_df, extention_df], ignore_index=False)\n",
        "        \n",
        "        explanations_df = explanations_df.sort_index().reset_index(drop=True)\n",
        "        print(\"after\", len(explanations_df))\n",
        "\n",
        "      collected_explanations.append(explanations_df)\n",
        "\n",
        "  print(\"total dupes\", dupes)\n",
        "  print(\"---\")\n",
        "  return collected_explanations, dupes\n",
        "\n",
        "\n",
        "\n",
        "def get_test_and_val_files(data_source):\n",
        "  test_dfs = {}\n",
        "  validation_dfs = {}\n",
        "  train_dfs = {}\n",
        "  file_names = [\"test.json\", \"validation.json\", \"train.json\"]\n",
        "\n",
        "  total_dupes = 0\n",
        "  for folder in data_source.iterdir():\n",
        "    if folder.is_dir() and not folder.name.startswith('.') and not folder.name.startswith('tabular'):\n",
        "      folder_name = str(folder.name)\n",
        "\n",
        "      (test_dfs[folder_name], validation_dfs[folder_name], train_dfs[folder_name]), dupes = get_dfs(folder, file_names)\n",
        "      total_dupes += dupes\n",
        "\n",
        "  test_df = pd.concat(test_dfs, ignore_index=True)\n",
        "  validation_df = pd.concat(validation_dfs, ignore_index=True)\n",
        "  train_df = pd.concat(train_dfs, ignore_index=True)\n",
        "  return test_df, validation_df, train_df, total_dupes\n",
        "\n",
        "test_df, val_df, train_df, dupes = get_test_and_val_files(data_source)\n",
        "\n",
        "print('----')\n",
        "print(\"dupes\", dupes)\n",
        "\n",
        "test_df.to_csv(data_source / 'test_df.csv')\n",
        "val_df.to_csv(data_source / 'val_df.csv')\n",
        "train_df.to_csv(data_source / 'train_df.csv')\n",
        "\n",
        "print(\"val\")\n",
        "print(val_df[\"explanations\"].isna().sum())\n",
        "print(len(val_df[\"explanations\"]))\n",
        "\n",
        "print(\"test\")\n",
        "print(test_df[\"explanations\"].isna().sum())\n",
        "print(len(test_df[\"explanations\"]))\n",
        "\n",
        "print(\"train\")\n",
        "print(train_df[\"explanations\"].isna().sum())\n",
        "print(len(train_df[\"explanations\"]))\n",
        "\n",
        "all_data = pd.concat([train_df, val_df, test_df]).reset_index(drop=True)\n",
        "all_data.to_csv(img_source / 'explanations_df.csv')\n",
        "print(\"total\", len(all_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5uNJGaThlVr",
        "outputId": "16dc87be-2e89-4c39-c768-9cf76a8394fc"
      },
      "outputs": [],
      "source": [
        "def dataframe_nan_count(base_path):\n",
        "  file_path = img_source / 'explanations_df.csv'\n",
        "  df = pd.read_csv(file_path)\n",
        "  print(len(df[\"explanations\"]))\n",
        "  print(df[\"explanations\"].isna().sum())\n",
        "\n",
        "dataframe_nan_count(base_source)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "28529\n",
        "422\n",
        "422"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data = pd.read_csv(img_source / 'explanations_df.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def shortener(x: str) -> str:\n",
        "    x_split = x.split('_')\n",
        "    if len(x_split) == 2:\n",
        "        part_one = x_split[0]\n",
        "        part_two = x_split[1].split('.')[0]\n",
        "        return (part_one + '_' + part_two)\n",
        "    else:\n",
        "        return '_'.join(x.split('_')[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data['TMA_identifier'] = all_data['TMA'].apply(shortener)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(all_data))\n",
        "print(all_data[['TMA_identifier', 'annotator']].groupby('TMA_identifier').nunique())\n",
        "unique_count = all_data[['TMA_identifier', 'annotator']].groupby('TMA_identifier').nunique()\n",
        "print('--')\n",
        "print(unique_count['annotator'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drop_images = ['PR1001_D7', 'PR1921c_B15', 'PR1921c_B16']\n",
        "\n",
        "print(\"len:\", len(all_data.groupby(['TMA_identifier'])))\n",
        "all_data = all_data[~all_data['TMA_identifier'].isin(drop_images)]\n",
        "print(\"lena:\", len(all_data.groupby(['TMA_identifier'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "drop_three_annotator_TMAs = []\n",
        "for name, series in all_data.groupby('TMA_identifier'):\n",
        "    if len(series['annotator'].unique()) != 3:\n",
        "        drop_three_annotator_TMAs.append(name)\n",
        "print(drop_three_annotator_TMAs)\n",
        "print(\"len\", len(drop_three_annotator_TMAs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(f\"{len(all_data)} in {len(all_data.groupby(['TMA_identifier']))}\")\n",
        "all_data = all_data[~all_data['TMA_identifier'].isin(drop_three_annotator_TMAs)]\n",
        "print(f\"{len(all_data)} in {len(all_data.groupby(['TMA_identifier']))}\")\n",
        "\n",
        "unique_count = all_data[['TMA_identifier', 'annotator']].groupby('TMA_identifier').nunique()\n",
        "print('--')\n",
        "print(unique_count['annotator'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_data = all_data.drop(columns=['TMA_identifier'])\n",
        "all_data.to_csv(img_source / \"shortened_df.csv\")\n",
        "print(all_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
