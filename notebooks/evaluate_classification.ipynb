{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Literal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import src.augmentations as augmentations\n",
    "import src.model_utils\n",
    "from src.gleason_data import GleasonX, prepare_torch_inputs\n",
    "from src.gleason_utils import create_composite_plot\n",
    "from src.lightning_modul import LitSegmenter\n",
    "import src.tree_loss as tree_loss\n",
    "from matplotlib import colormaps as cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "from src.tree_loss import generate_label_hierarchy\n",
    "from torchmetrics import Accuracy, ConfusionMatrix\n",
    "from src.lightning_modul import LitClassifier\n",
    "from src.gleason_data import GleasonXClassification\n",
    "from itertools import zip_longest\n",
    "import math\n",
    "from textwrap import wrap\n",
    "import torchvision.transforms as tt\n",
    "from ipywidgets import widgets\n",
    "from monai.inferers import *\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from torch.utils.data import Subset\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import ipywidgets.widgets as wid\n",
    "from PIL import Image\n",
    "import albumentations as alb\n",
    "import sklearn\n",
    "import ipywidgets as wid\n",
    "\n",
    "import sys\n",
    "import sklearn.metrics\n",
    "from monai.inferers import sliding_window_inference\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sys.modules[\"tree_loss\"] = sys.modules[\"src.tree_loss\"]\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    sys.modules[\"robust_loss_functions\"] = sys.modules[\"src.robust_loss_functions\"]\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    sys.modules[\"loss_functions\"] = sys.modules[\"src.loss_functions\"]\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    sys.modules[\"augmentations\"] = sys.modules[\"src.augmentations\"]\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "\n",
    "try:\n",
    "    sys.modules[\"model_utils\"] = sys.modules[\"src.model_utils\"]\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/datasets/GleasonXAI\"\n",
    "DATA_PATH = Path(DATA_PATH)\n",
    "\n",
    "model_base_path = [Path(\"~/experiments/Gleason/GleasonClassification\").expanduser()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "label_level = 1\n",
    "\n",
    "def find_best_models(base_paths):\n",
    "    exp_dict = {}\n",
    "    for base_path in base_paths:\n",
    "        for model_path in Path(base_path).glob(\"**/*.ckpt\"):\n",
    "            experiment_path = Path(model_path).relative_to(base_path.parent)\n",
    "            *experiment_super_folders, experiment_name, version_number, checkpoints, model_name = experiment_path.parts\n",
    "\n",
    "            if len(experiment_super_folders) > 1:\n",
    "                experiment_super_folder = str(Path(os.path.join(*experiment_super_folders[1:])))\n",
    "            elif len(experiment_super_folders) == 0:\n",
    "                experiment_super_folder = \"\"\n",
    "            else:\n",
    "                experiment_super_folder = experiment_super_folders[0]\n",
    "\n",
    "\n",
    "            # experiment_path = model_path.parent.parent  # Get experiment directory\n",
    "            # experiment_name = experiment_path.name\n",
    "            # version_number = experiment_path.parent.name\n",
    "            exp_name = f\"{experiment_super_folder}/{experiment_name}/{version_number}\"\n",
    "\n",
    "            if exp_name in exp_dict and not \"best_model\" in model_name:\n",
    "                continue\n",
    "            exp_dict[exp_name] = model_path\n",
    "    return exp_dict\n",
    "\n",
    "model_dict = find_best_models(model_base_path)\n",
    "\n",
    "\n",
    "transforms_dict = {\"1024\": augmentations.basic_transforms_val_test_scaling1024,\n",
    "                      \"2048\": augmentations.basic_transforms_val_test_scaling2048, \"512\": augmentations.basic_transforms_val_test_scaling512, \"center\": augmentations.basic_transforms_val_test, \"random\": augmentations.basic_random_crop_val_test, \"efficient_net_random\":augmentations.effb4_random_crop_val_test}\n",
    "\n",
    "\n",
    "classification_model = None\n",
    "dataset = None\n",
    "dataset_seg = None\n",
    "dataloader = None\n",
    "dataloader_seg = None\n",
    "num_classes  = None\n",
    "split = None\n",
    "transforms_scaling = None\n",
    "model_path = None\n",
    "label_file = None\n",
    "scaling = None\n",
    "transform = None\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "\n",
    "def create_model_dataset():\n",
    "    global model, dataset, dataset_seg, num_classes, split, transforms_scaling\n",
    "\n",
    "    # Create drowdown\n",
    "    def c_d(options, value=None, desc=\"\"):\n",
    "        if value is None:\n",
    "            value = options[0]\n",
    "        return wid.Dropdown(options=options, value=value, description=desc)\n",
    "    \n",
    "\n",
    "    model_dropdown = c_d(sorted(list(model_dict.keys())), desc=\"model\")\n",
    "    split_dropdown = c_d([\"train\", \"val\", \"test\", \"all\"], \"val\", \"split\")\n",
    "    scaling_dropdown = c_d([\"original\", \"1024\", \"2048\"],  desc=\"Scaling\")\n",
    "    transform_drowdown = c_d(list(transforms_dict.keys()), desc=\"Transform\")\n",
    "    label_file_dropdown = c_d([\"label_remapping.json\", \"label_remapping_coarser.json\"], desc=\"label file\")\n",
    "\n",
    "    status_label = wid.Label(value=\"Status: up-to-date\", color=\"green\")\n",
    "\n",
    "    def create_model(*args):\n",
    "\n",
    "        global classification_model, model_path\n",
    "\n",
    "        SELECTED_MODEL = model_dropdown.value\n",
    "        \n",
    "        model_path = model_dict[SELECTED_MODEL]\n",
    "        classification_model = LitClassifier.load_from_checkpoint(model_path)\n",
    "\n",
    "    \n",
    "    def create_dataset(*args):\n",
    "\n",
    "        global dataset, dataset_seg, dataloader, dataloader_seg, split, num_classes, transforms_scaling, scaling, label_file\n",
    "\n",
    "        SELECTED_SPLIT = split_dropdown.value\n",
    "        SELECTED_SCALING = scaling_dropdown.value\n",
    "        SELECTED_TRANSFORM = transform_drowdown.value\n",
    "        SELECTED_LABEL_FILE = label_file_dropdown.value\n",
    "\n",
    "        transform = SELECTED_TRANSFORM\n",
    "        scaling = SELECTED_SCALING\n",
    "        label_file = SELECTED_LABEL_FILE\n",
    "        split = SELECTED_SPLIT\n",
    "        transform_scaling = transforms_dict[SELECTED_TRANSFORM]\n",
    "\n",
    "        dataset = GleasonXClassification(DATA_PATH, SELECTED_SPLIT, scaling=SELECTED_SCALING, transforms=transform_scaling,\n",
    "                                         label_level=label_level, label_hierarchy_file=SELECTED_LABEL_FILE)\n",
    "\n",
    "        dataset_seg = GleasonX(DATA_PATH, split=SELECTED_SPLIT, scaling=SELECTED_SCALING,\n",
    "                               transforms=transform_scaling, label_level=label_level, label_hierarchy_file=SELECTED_LABEL_FILE)\n",
    "        \n",
    "        dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=False)\n",
    "        dataloader_seg = DataLoader(dataset=dataset_seg, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=False)\n",
    "\n",
    "        num_classes = dataset.num_classes\n",
    "\n",
    "    #create_model()\n",
    "    #create_dataset()\n",
    "\n",
    "    def obs_wid(wids, observable):\n",
    "        for w in wids:\n",
    "            w.observe(observable)\n",
    "    \n",
    "\n",
    "\n",
    "    def on_button_click(*args):\n",
    "\n",
    "        status_label.value = \"Status: Running\"\n",
    "        status_label.style = {\"color\": \"yellow\"}\n",
    "        create_model()\n",
    "        create_dataset()\n",
    "\n",
    "        status_label.value = \"Status: up-to-date\"\n",
    "        status_label.style = {\"color\": \"green\"}\n",
    "\n",
    "\n",
    "    def on_change(change):\n",
    "        status_label.value = \"Status: needs update\"\n",
    "        status_label.style = {\"color\": \"red\"}\n",
    "    \n",
    "\n",
    "    button = wid.Button(description=\"Update\")\n",
    "    button.on_click(on_button_click)\n",
    "\n",
    "    obs_wid([model_dropdown, split_dropdown, scaling_dropdown, transform_drowdown, label_file_dropdown], on_change)\n",
    "\n",
    "    menu = wid.VBox([model_dropdown, split_dropdown, scaling_dropdown, transform_drowdown, label_file_dropdown, status_label, button])\n",
    "\n",
    "    return menu\n",
    "\n",
    "\n",
    "menu = create_model_dataset()\n",
    "menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "\n",
    "iterations = 5\n",
    "\n",
    "for it in range(iterations):\n",
    "    for batch in tqdm(dataloader):\n",
    "\n",
    "        imgs, masks, background_masks = batch  # STATISTICS_DATASET[i]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outs = classification_model(imgs.to(device))\n",
    "            preds.append(outs)\n",
    "            labels.append(masks)\n",
    "\n",
    "preds = torch.cat(preds, dim=0).cpu()\n",
    "sigmoids = torch.nn.functional.sigmoid(preds)\n",
    "labels = torch.cat(labels).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = dataset.classes_named #[\"Benign\", \"3\", \"4\", \"5\"]\n",
    "\n",
    "f, ax = plt.subplots(2,2)\n",
    "f.tight_layout()\n",
    "ax = ax.T\n",
    "thresholds = torch.linspace(0,1,100)\n",
    "at_least_once = labels > 0.0\n",
    "majority = labels >= 0.5\n",
    "\n",
    "\n",
    "def get_accs_at_level(inputs, targets, threshold):\n",
    "    return ((inputs >= threshold) == targets).float().mean(dim=0)\n",
    "\n",
    "\n",
    "for a, targets, title in zip(ax,[at_least_once, majority], [\"once\", \"majority\"]):\n",
    "\n",
    "\n",
    "    accs_at_level = torch.stack([get_accs_at_level(sigmoids, targets, t) for t in thresholds])\n",
    "\n",
    "    for i, (cl, c) in enumerate(zip(dataset.classes_named, dataset.colormap.colors)):\n",
    "        fpr, tpr, _ = sklearn.metrics.roc_curve(targets.numpy()[:, i], sigmoids.numpy()[:, i])\n",
    "        precision, recall , _ =  sklearn.metrics.precision_recall_curve(targets.numpy()[:, i], sigmoids.numpy()[:, i])\n",
    "\n",
    "        a[0].plot(fpr, tpr, label=cl + f\" AUROC:{float(sklearn.metrics.auc(fpr, tpr)):.2f}, AUPRC:{float(sklearn.metrics.auc(recall, precision)):.2f}\", color=c)\n",
    "        a[0].set_xlabel(\"FPR\")\n",
    "        a[0].set_ylabel(\"TPR\")\n",
    "        a[0].set_title(title)\n",
    "\n",
    "        a[1].plot(recall, precision, label=cl + f\" AUROC:{float(sklearn.metrics.auc(fpr, tpr)):.2f}, AUPRC:{float(sklearn.metrics.auc(recall, precision)):.2f}\", color=c)\n",
    "        a[1].set_xlabel(\"Recall\")\n",
    "        a[1].set_ylabel(\"Precision\")\n",
    "\n",
    "        a[1].set_title(title)\n",
    "\n",
    "    a[0].plot([0,1], [0,1], color=\"k\", linestyle=\"--\", label=\"Random guess\")\n",
    "    a[1].plot([0,1], [1,0], color=\"k\", linestyle=\"--\")\n",
    "plt.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='center left')  # Move legend to the right\n",
    "\n",
    "img_save_path = Path(\"./results\"/model_path.relative_to(model_base_path[0]).parents[2])\n",
    "img_save_path.mkdir(exist_ok=True, parents=True)\n",
    "plt.savefig(img_save_path/\"curves.png\")\n",
    "\n",
    "def find_optimal_thresholds(inputs, targets, thresholds):\n",
    "    accs_at_level = torch.stack([get_accs_at_level(inputs, targets, t) for t in thresholds])\n",
    "\n",
    "    best_accs_per_class, t_index = torch.max(accs_at_level, dim=0)\n",
    "\n",
    "    best_thresholds = [float(thresholds[t]) for t in t_index]\n",
    "\n",
    "    return best_accs_per_class, best_thresholds\n",
    "\n",
    "\n",
    "bestaccsclass, class_threshold = find_optimal_thresholds(sigmoids, majority, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_class_scores = {}\n",
    "prrec_class_scores = {}\n",
    "class_size = {}\n",
    "\n",
    "for i, class_name in enumerate(dataset.classes_named[1:9], start=1):\n",
    "\n",
    "    roc_class_scores[(\"once\", class_name)] = sklearn.metrics.roc_auc_score(at_least_once.numpy()[:, i], sigmoids.numpy()[:, i])\n",
    "    roc_class_scores[(\"majority\", class_name)] = sklearn.metrics.roc_auc_score(majority.numpy()[:, i], sigmoids.numpy()[:, i])\n",
    "    prrec_class_scores[(\"once\", class_name)] = sklearn.metrics.average_precision_score(at_least_once.numpy()[:, i], sigmoids.numpy()[:, i])\n",
    "    prrec_class_scores[(\"majority\", class_name)] = sklearn.metrics.average_precision_score(majority.numpy()[:, i], sigmoids.numpy()[:, i])\n",
    "    class_size[(\"once\", class_name)] = at_least_once[:, i].sum(axis=0).item()\n",
    "    class_size[(\"majority\", class_name)] = majority[:,i].sum(axis=0).item()\n",
    "    \n",
    "result_df = pd.concat([pd.Series(roc_class_scores), pd.Series(prrec_class_scores), pd.Series(class_size)], axis=\"columns\")\n",
    "result_df.columns = [\"AUROC\", \"AUCPRC\", \"class_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.sort_index()\n",
    "result_df.index = result_df.index.set_names([\"label_type\", \"class\"])\n",
    "result_df = result_df.reset_index()\n",
    "result_df[\"run\"] = model_path.relative_to(model_base_path[0])\n",
    "result_df[\"split\"] = split\n",
    "result_df[\"scaling\"] = scaling\n",
    "result_df[\"label_file\"] = label_file\n",
    "result_df[\"label_level\"] = label_level\n",
    "result_df[\"label_file\"] = label_file\n",
    "result_df = result_df.set_index(keys=[\"run\", \"split\", \"scaling\", \"label_level\", \"label_file\", \"label_type\", \"class\"])\n",
    "\n",
    "if not (img_save_path/\"result_frame.csv\").exists():\n",
    "    result_df.to_csv(img_save_path/\"result_frame.csv\")\n",
    "else:\n",
    "    old_frame = pd.read_csv(img_save_path/\"result_frame.csv\")\n",
    "    old_frame = old_frame.set_index(keys=[\"run\", \"split\", \"scaling\", \"label_level\", \"label_file\", \"label_type\", \"class\"])\n",
    "\n",
    "    merged_frame = pd.merge(old_frame, result_df, how=\"outer\", left_index=True, right_index=True, )\n",
    "    \n",
    "    old_frame = pd.concat([old_frame, result_df], axis=\"index\", ignore_index=True)\n",
    "    old_frame.to_csv(img_save_path/\"result_frame.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({\"A\":[\"a\",\"b\",\"c\"], \"B\":[0,1,2] }, index=[0,1,2])\n",
    "b = pd.DataFrame({\"A\":[\"d\",\"e\",\"f\"], \"B\":[2,4,5] },index=[3,4,5])\n",
    "pd.merge(a,b, how=\"outer\", on=[\"B\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_freq_maj = [majority.numpy()[:,i].sum()/len(majority) for i in range(majority.shape[1])]\n",
    "class_freq_ao = [at_least_once.numpy()[:, i].sum()/len(at_least_once) for i in range(at_least_once.shape[1])]\n",
    "pred_freq = [(sigmoids.numpy()[:, i]>= thres).sum()/len(at_least_once) for i, thres in enumerate(class_threshold)]\n",
    "\n",
    "num_plots = 3\n",
    "\n",
    "_= plt.bar(np.arange(num_classes)-(1/(2*num_plots)),class_freq_maj, width=1/(2*num_plots))\n",
    "_ = plt.bar(np.arange(num_classes), class_freq_ao, width=1/(2*num_plots))\n",
    "_ = plt.bar(np.arange(num_classes)+(1/(2*num_plots)), pred_freq, width=1/(2*num_plots))\n",
    "\n",
    "pred_freq\n",
    "\n",
    "_=plt.xticks(range(num_classes), [cl if len(cl)<20 else cl[:20-3]+\"...\" for cl in classes], rotation=45, horizontalalignment=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "class SplattingClassifier(LitClassifier):\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        out = super().forward(x, *args, **kwargs)\n",
    "\n",
    "        b, _, h, w = x.shape\n",
    "        out_large = torch.zeros((b, out.shape[1], h, w), device=out.device)\n",
    "\n",
    "        for b_i in range(b):\n",
    "            for c_i in range(out.shape[1]):\n",
    "                out_large[b_i, c_i, :, :] = out[b_i, c_i]\n",
    "        return out_large\n",
    "\n",
    "\n",
    "sc = SplattingClassifier.load_from_checkpoint(model_path).to(device)\n",
    "sc.model = sc.model.to(device)\n",
    "segmentation_dataset = GleasonX(DATA_PATH, split=split, scaling=\"original\", transforms=augmentations.basic_transforms_val_test_scaling1024, label_level=label_level)\n",
    "sw_inf = SlidingWindowInferer(roi_size=(512, 512), sw_batch_size=4, overlap=0.9, mode=\"gaussian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "@widgets.interact(idx=widgets.IntSlider(0, 0,100), apply_background=True)\n",
    "def plot_class(idx, apply_background):\n",
    "\n",
    "    img, masks, background_mask = segmentation_dataset.get(idx, False)\n",
    "    img_torch = torchvision.transforms.functional.to_tensor(img)\n",
    "    \n",
    "    #org_img = segmentation_dataset.get_raw_image(idx)\n",
    "    with torch.no_grad():\n",
    "        out = classification_model(img_torch.unsqueeze(0).to(device)).squeeze().detach().cpu().numpy()\n",
    "        out_seg = sw_inf(img_torch.unsqueeze(0).to(device), sc).squeeze().detach().cpu().numpy()\n",
    "\n",
    "    f, axes = plt.subplots(2,3 + math.ceil(segmentation_dataset.num_classes/2))\n",
    "    axes = axes.T.flatten()\n",
    "\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_axis_off()\n",
    "\n",
    "\n",
    "    axes[1].set_axis_off()\n",
    "    class_mask = np.zeros_like(masks[0])\n",
    "    x_len = class_mask.shape[0]\n",
    "    print(out >= class_threshold)\n",
    "    for i in range(len(out)):\n",
    "        if out[i] >= class_threshold[i]:\n",
    "            class_mask[:, i*x_len//len(out):(i+1)*x_len//len(out)] = i+1\n",
    "\n",
    "\n",
    "    class_cmap = ListedColormap(np.concatenate([np.array([[0,0,0,1]]), segmentation_dataset.colormap.colors]))\n",
    "    axes[1].imshow(class_mask, cmap=class_cmap, vmin=0, vmax=segmentation_dataset.num_classes)\n",
    "\n",
    "\n",
    "    for ax, mask in zip_longest(axes[2:6], masks):\n",
    "        if ax is not None and mask is not None:\n",
    "\n",
    "            if apply_background:\n",
    "                mask += 1\n",
    "                mask[background_mask] = 0.0\n",
    "                used_cmap = class_cmap\n",
    "                ax.imshow(mask.astype(int), used_cmap, vmin=0, vmax=segmentation_dataset.num_classes)\n",
    "\n",
    "            else:\n",
    "                used_cmap = segmentation_dataset.colormap\n",
    "                ax.imshow(mask.astype(int), used_cmap, vmin=0, vmax=segmentation_dataset.num_classes-1)\n",
    "        \n",
    "        if ax is not None:\n",
    "            ax.set_axis_off()\n",
    "\n",
    "    for i,ax in enumerate(axes[6:6+segmentation_dataset.num_classes+1]):\n",
    "\n",
    "        tmp_cmap = ListedColormap(np.concatenate([np.array([[0, 0, 0, 1]]), [segmentation_dataset.colormap.colors[i]]]))\n",
    "\n",
    "        pred_class_mask = out_seg[i] >= class_threshold[i]\n",
    "\n",
    "        if apply_background:\n",
    "            pred_class_mask[background_mask] = 0.0\n",
    "\n",
    "        ax.imshow(pred_class_mask, cmap=tmp_cmap, vmin=0, vmax=1)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(segmentation_dataset.classes_named[i][:25], size=8, rotation=45, horizontalalignment=\"left\")\n",
    "\n",
    "\n",
    "    _ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _, _ = segmentation_dataset.get(0, False)\n",
    "img = torchvision.transforms.functional.to_tensor(img).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_splated = sw_inf(img, sc)\n",
    "\n",
    "plt.imshow(out_splated[0, 1].cpu().detach().numpy(), cmap=cm[\"Greys\"].reversed())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GleasonXAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
